<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[[Zabbix] zabbix监控cassandra数据库]]></title>
    <url>%2F2018%2F08%2F27%2Fzabbix%E7%9B%91%E6%8E%A7cassandra%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[1、安装java_gate_way,如果当前监控架构为client-server将zabbix-java-gate-way安装在server端口，如果当前架构为client-proxy-server,将zabbix-java-gate-way安装在proxy端，安装步骤如下（下面以client-proxy-server架构为例）：123456789101112131415创建zabbix用户，安装依赖包：sudo bashmkdir /home/zabbixuseradd -r -s /sbin/nologin zabbixyum -y install gcc gcc-c++ pcre-devel openssl-develyum -y install java-1.8.0-openjdk java-1.8.0-openjdk-devel上传zabbix安装包，并安装java-gate-way： mv /data/download/zabbix-3.4.2.tar.gz /home/zabbix/ cd /home/zabbix/tar -zxvf zabbix-3.4.2.tar.gzcd zabbix-3.4.2./configure --prefix=/data/zabbix --enable-java(如果zabbix-porxy或zabbix-server已安装，可指定一个新路径，gate-way与proxy、server并没有直接关系，可不必一起安装；如果都没有安装，为了管理方便，亦可放到同一目录）make &amp;&amp; make install 安装完成之后，会在指定目录下存在以下文件：1234567ll /data/zabbix/sbin/zabbix_java/total 12drwxr-xr-x. 2 root root 65 Aug 23 02:41 bindrwxr-xr-x. 2 root root 177 Aug 23 02:36 lib-rw-r--r--. 1 root root 791 Aug 23 02:36 settings.sh-rwxr-xr-x. 1 root root 545 Aug 23 02:36 shutdown.sh-rwxr-xr-x. 1 root root 2025 Aug 23 02:36 startup.sh 包括启动脚本，关闭脚本，配置文件，依赖库，运行命令等文件。启动java_gate_way：1./startup.sh 2、安装完成之后，修改zabbix_proxy.conf配置文件，添加以下参数：123JavaGateway=127.0.0.1JavaGatewayPort=10052StartJavaPollers=5 默认端口为10052，因为zabbix-proxy与gate-way在同一台服务器上，因此使用127.0.0.1即可。必须指定java轮询器的预分叉实例数，默认情况下启动不会启动与jmx监控相关的进程。修改完成之后重新启动zabbix-proxy服务，是修改参数生效。 3、修改cassandra-java启动参数，使其jmx监控进程允许其他服务器访问cat /etc/cassandra/conf/cassandra-env.sh |grep -v ‘^#’ |grep -v ‘^$’123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172calculate_heap_sizes()&#123; case &quot;`uname`&quot; in Linux) system_memory_in_mb=`free -m | awk &apos;/:/ &#123;print $2;exit&#125;&apos;` system_cpu_cores=`egrep -c &apos;processor([[:space:]]+):.*&apos; /proc/cpuinfo` ;; FreeBSD) system_memory_in_bytes=`sysctl hw.physmem | awk &apos;&#123;print $2&#125;&apos;` system_memory_in_mb=`expr $system_memory_in_bytes / 1024 / 1024` system_cpu_cores=`sysctl hw.ncpu | awk &apos;&#123;print $2&#125;&apos;` ;; SunOS) system_memory_in_mb=`prtconf | awk &apos;/Memory size:/ &#123;print $3&#125;&apos;` system_cpu_cores=`psrinfo | wc -l` ;; Darwin) system_memory_in_bytes=`sysctl hw.memsize | awk &apos;&#123;print $2&#125;&apos;` system_memory_in_mb=`expr $system_memory_in_bytes / 1024 / 1024` system_cpu_cores=`sysctl hw.ncpu | awk &apos;&#123;print $2&#125;&apos;` ;; *) # assume reasonable defaults for e.g. a modern desktop or # cheap server system_memory_in_mb=&quot;2048&quot; system_cpu_cores=&quot;2&quot; ;; esac # some systems like the raspberry pi don&apos;t report cores, use at least 1 if [ &quot;$system_cpu_cores&quot; -lt &quot;1&quot; ] then system_cpu_cores=&quot;1&quot; fi # set max heap size based on the following # max(min(1/2 ram, 1024MB), min(1/4 ram, 8GB)) # calculate 1/2 ram and cap to 1024MB # calculate 1/4 ram and cap to 8192MB # pick the max half_system_memory_in_mb=`expr $system_memory_in_mb / 2` quarter_system_memory_in_mb=`expr $half_system_memory_in_mb / 2` if [ &quot;$half_system_memory_in_mb&quot; -gt &quot;1024&quot; ] then half_system_memory_in_mb=&quot;1024&quot; fi if [ &quot;$quarter_system_memory_in_mb&quot; -gt &quot;8192&quot; ] then quarter_system_memory_in_mb=&quot;8192&quot; fi if [ &quot;$half_system_memory_in_mb&quot; -gt &quot;$quarter_system_memory_in_mb&quot; ] then max_heap_size_in_mb=&quot;$half_system_memory_in_mb&quot; else max_heap_size_in_mb=&quot;$quarter_system_memory_in_mb&quot; fi MAX_HEAP_SIZE=&quot;$&#123;max_heap_size_in_mb&#125;M&quot; # Young gen: min(max_sensible_per_modern_cpu_core * num_cores, 1/4 * heap size) max_sensible_yg_per_core_in_mb=&quot;100&quot; max_sensible_yg_in_mb=`expr $max_sensible_yg_per_core_in_mb &quot;*&quot; $system_cpu_cores` desired_yg_in_mb=`expr $max_heap_size_in_mb / 4` if [ &quot;$desired_yg_in_mb&quot; -gt &quot;$max_sensible_yg_in_mb&quot; ] then HEAP_NEWSIZE=&quot;$&#123;max_sensible_yg_in_mb&#125;M&quot; else HEAP_NEWSIZE=&quot;$&#123;desired_yg_in_mb&#125;M&quot; fi&#125;java_ver_output=`&quot;$&#123;JAVA:-java&#125;&quot; -version 2&gt;&amp;1`jvmver=`echo &quot;$java_ver_output&quot; | grep &apos;[openjdk|java] version&apos; | awk -F&apos;&quot;&apos; &apos;NR==1 &#123;print $2&#125;&apos; | cut -d\- -f1`JVM_VERSION=$&#123;jvmver%_*&#125;JVM_PATCH_VERSION=$&#123;jvmver#*_&#125;if [ &quot;$JVM_VERSION&quot; \&lt; &quot;1.8&quot; ] ; then echo &quot;Cassandra 3.0 and later require Java 8u40 or later.&quot; exit 1;fiif [ &quot;$JVM_VERSION&quot; \&lt; &quot;1.8&quot; ] &amp;&amp; [ &quot;$JVM_PATCH_VERSION&quot; -lt 40 ] ; then echo &quot;Cassandra 3.0 and later require Java 8u40 or later.&quot; exit 1;fijvm=`echo &quot;$java_ver_output&quot; | grep -A 1 &apos;java version&apos; | awk &apos;NR==2 &#123;print $1&#125;&apos;`case &quot;$jvm&quot; in OpenJDK) JVM_VENDOR=OpenJDK # this will be &quot;64-Bit&quot; or &quot;32-Bit&quot; JVM_ARCH=`echo &quot;$java_ver_output&quot; | awk &apos;NR==3 &#123;print $2&#125;&apos;` ;; &quot;Java(TM)&quot;) JVM_VENDOR=Oracle # this will be &quot;64-Bit&quot; or &quot;32-Bit&quot; JVM_ARCH=`echo &quot;$java_ver_output&quot; | awk &apos;NR==3 &#123;print $3&#125;&apos;` ;; *) # Help fill in other JVM values JVM_VENDOR=other JVM_ARCH=unknown ;;esacJVM_OPTS=&quot;$JVM_OPTS -Xloggc:/var/log/cassandra/gc.log&quot;JVM_OPTS_FILE=$CASSANDRA_CONF/jvm.optionsfor opt in `grep &quot;^-&quot; $JVM_OPTS_FILE`do JVM_OPTS=&quot;$JVM_OPTS $opt&quot;doneecho $JVM_OPTS | grep -q XmnDEFINED_XMN=$?echo $JVM_OPTS | grep -q XmxDEFINED_XMX=$?echo $JVM_OPTS | grep -q XmsDEFINED_XMS=$?echo $JVM_OPTS | grep -q UseConcMarkSweepGCUSING_CMS=$?echo $JVM_OPTS | grep -q UseG1GCUSING_G1=$?if [ &quot;x$MAX_HEAP_SIZE&quot; = &quot;x&quot; ] &amp;&amp; [ &quot;x$HEAP_NEWSIZE&quot; = &quot;x&quot; -o $USING_G1 -eq 0 ]; then calculate_heap_sizeselif [ &quot;x$MAX_HEAP_SIZE&quot; = &quot;x&quot; ] || [ &quot;x$HEAP_NEWSIZE&quot; = &quot;x&quot; -a $USING_G1 -ne 0 ]; then echo &quot;please set or unset MAX_HEAP_SIZE and HEAP_NEWSIZE in pairs when using CMS GC (see cassandra-env.sh)&quot; exit 1fiif [ &quot;x$MALLOC_ARENA_MAX&quot; = &quot;x&quot; ] ; then export MALLOC_ARENA_MAX=4fiif [ $DEFINED_XMX -ne 0 ] &amp;&amp; [ $DEFINED_XMS -ne 0 ]; then JVM_OPTS=&quot;$JVM_OPTS -Xms$&#123;MAX_HEAP_SIZE&#125;&quot; JVM_OPTS=&quot;$JVM_OPTS -Xmx$&#123;MAX_HEAP_SIZE&#125;&quot;elif [ $DEFINED_XMX -ne 0 ] || [ $DEFINED_XMS -ne 0 ]; then echo &quot;Please set or unset -Xmx and -Xms flags in pairs on jvm.options file.&quot; exit 1fiif [ $DEFINED_XMN -eq 0 ] &amp;&amp; [ $DEFINED_XMX -ne 0 ]; then echo &quot;Please set or unset -Xmx and -Xmn flags in pairs on jvm.options file.&quot; exit 1elif [ $DEFINED_XMN -ne 0 ] &amp;&amp; [ $USING_CMS -eq 0 ]; then JVM_OPTS=&quot;$JVM_OPTS -Xmn$&#123;HEAP_NEWSIZE&#125;&quot;fiif [ &quot;$JVM_ARCH&quot; = &quot;64-Bit&quot; ] &amp;&amp; [ $USING_CMS -eq 0 ]; then JVM_OPTS=&quot;$JVM_OPTS -XX:+UseCondCardMark&quot;fiJVM_OPTS=&quot;$JVM_OPTS -XX:CompileCommandFile=$CASSANDRA_CONF/hotspot_compiler&quot;JVM_OPTS=&quot;$JVM_OPTS -javaagent:$CASSANDRA_HOME/lib/jamm-0.3.0.jar&quot;if [ &quot;x$CASSANDRA_HEAPDUMP_DIR&quot; != &quot;x&quot; ]; then JVM_OPTS=&quot;$JVM_OPTS -XX:HeapDumpPath=$CASSANDRA_HEAPDUMP_DIR/cassandra-`date +%s`-pid$$.hprof&quot;fiJVM_ON_OUT_OF_MEMORY_ERROR_OPT=&quot;-XX:OnOutOfMemoryError=kill -9 %p&quot;JVM_OPTS=&quot;$JVM_OPTS -Djava.rmi.server.hostname=10.0.7.50&quot;if [ &quot;x$LOCAL_JMX&quot; = &quot;x&quot; ]; then LOCAL_JMX=nofiJMX_PORT=&quot;7199&quot;if [ &quot;$LOCAL_JMX&quot; = &quot;yes&quot; ]; then JVM_OPTS=&quot;$JVM_OPTS -Dcassandra.jmx.local.port=$JMX_PORT&quot; JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;else JVM_OPTS=&quot;$JVM_OPTS -Dcassandra.jmx.remote.port=$JMX_PORT&quot; # if ssl is enabled the same port cannot be used for both jmx and rmi so either # pick another value for this property or comment out to use a random port (though see CASSANDRA-7087 for origins) JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.rmi.port=$JMX_PORT&quot; # turn on JMX authentication. See below for further options JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot; # jmx ssl options JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot; #JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.ssl.need.client.auth=true&quot; #JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.ssl.enabled.protocols=&lt;enabled-protocols&gt;&quot; #JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.ssl.enabled.cipher.suites=&lt;enabled-cipher-suites&gt;&quot; #JVM_OPTS=&quot;$JVM_OPTS -Djavax.net.ssl.keyStore=/path/to/keystore&quot; #JVM_OPTS=&quot;$JVM_OPTS -Djavax.net.ssl.keyStorePassword=&lt;keystore-password&gt;&quot; #JVM_OPTS=&quot;$JVM_OPTS -Djavax.net.ssl.trustStore=/path/to/truststore&quot; #JVM_OPTS=&quot;$JVM_OPTS -Djavax.net.ssl.trustStorePassword=&lt;truststore-password&gt;&quot;fiJVM_OPTS=&quot;$JVM_OPTS -Djava.library.path=$CASSANDRA_HOME/lib/sigar-bin&quot;JVM_OPTS=&quot;$JVM_OPTS $MX4J_ADDRESS&quot;JVM_OPTS=&quot;$JVM_OPTS $MX4J_PORT&quot;JVM_OPTS=&quot;$JVM_OPTS $JVM_EXTRA_OPTS&quot; 主要修改一下内容，默认LOCAL_JMX=yes123if [ &quot;x$LOCAL_JMX&quot; = &quot;x&quot; ]; then LOCAL_JMX=nofi 将true改为false,修改远程访问认证无需密码：12345678910if [ &quot;$LOCAL_JMX&quot; = &quot;yes&quot; ]; then JVM_OPTS=&quot;$JVM_OPTS -Dcassandra.jmx.local.port=$JMX_PORT&quot; JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;else JVM_OPTS=&quot;$JVM_OPTS -Dcassandra.jmx.remote.port=$JMX_PORT&quot; # if ssl is enabled the same port cannot be used for both jmx and rmi so either # pick another value for this property or comment out to use a random port (though see CASSANDRA-7087 for origins) JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.rmi.port=$JMX_PORT&quot; # turn on JMX authentication. See below for further options JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot; 4、在zabbix-proxy端测试，获取被监控端的数据是否正常，监控脚本如下：cat /data/zabbix/sbin/zabbix_java/bin/zabbix_get_jmx12345678910111213141516171819202122232425262728#!/usr/bin/env bashif [ $# != 5 ]then echo &quot;Usage: $0 &lt;JAVA_GATEWAY_HOST&gt; &lt;JAVA_GATEWAY_PORT&gt; &lt;JMX_SERVER&gt; &lt;JMX_PORT&gt; &lt;KEY&gt;&quot; exit;fi# create connectionexec 3&lt;&gt;/dev/tcp/$1/$2# compose messageMSG=&quot;&#123;\&quot;request\&quot;: \&quot;java gateway jmx\&quot;,\&quot;jmx_endpoint\&quot;:\&quot;service:jmx:rmi:///jndi/rmi://$3:$4/jmxrmi\&quot;,\&quot;keys\&quot;: [\&quot;$5\&quot;]&#125;&quot;# write message length as zero-padded 16-digit hexadecimal numberprintf -v LEN &apos;%016x&apos; &quot;$&#123;#MSG&#125;&quot;# prepare message length in little endian representationBYTES=&quot;&quot;for i in &#123;0..14..2&#125;do BYTES=&quot;\\x$&#123;LEN:$i:2&#125;$BYTES&quot;done# prepend protocol header and message lengthprintf &quot;ZBXD\\1$BYTES%s&quot; &quot;$MSG&quot; &gt;&amp;3# output the result skipping 5 bytes of &quot;ZBXD\\1&quot; header and 8 bytes of message lengthtail -c+13 &lt;&amp;3 该脚本可自行存放，没有规定，测试命令如下：1./zabbix_get_jmx 127.0.0.1 10052 10.0.7.50 7199 &apos;jmx[\&quot;org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=MemtablePostFlush,name=ActiveTasks\&quot;,\&quot;Value\&quot;]&apos; 127.0.0.1:为java-gate-way地址；10052：为java-gate-way端口；10.0.7.50：为被监控端的ip地址；7199：为被监控端jmx的端口；org.apache**:为要获取的参数，需要获取哪些参数可查看官方文档 5、zabbix官网提供了对cassandra的监控模板，其中有部分参数已失效，如需下载官方模板，点击此处，该模板为纯英文，且里面参数没有详细描述，下面为根据个人理解翻译后的模板，点击此处下载]]></content>
      <tags>
        <tag>zabbix</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Linux] centos7.2 服务器 使用df -h卡死问题]]></title>
    <url>%2F2018%2F08%2F23%2Fcentos7.2%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8df%20-h%E5%8D%A1%E6%AD%BB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1、服务器使用df -h命令卡死，crtl+c没有反应，ps -ef|grep df 命令杀掉df -h进程也无效。2、重新启动会话，使用strace跟踪df -h执行状态strace df -h12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182execve(&quot;/usr/bin/df&quot;, [&quot;df&quot;, &quot;-h&quot;], [/* 24 vars */]) = 0brk(NULL) = 0x1e9c000mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77097000access(&quot;/etc/ld.so.preload&quot;, R_OK) = -1 ENOENT (No such file or directory)open(&quot;/etc/ld.so.cache&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=19527, ...&#125;) = 0mmap(NULL, 19527, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe77092000close(3) = 0open(&quot;/lib64/libc.so.6&quot;, O_RDONLY|O_CLOEXEC) = 3read(3, &quot;\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0 \34\2\0\0\0\0\0&quot;..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=2107816, ...&#125;) = 0mmap(NULL, 3932736, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7efe76ab6000mprotect(0x7efe76c6c000, 2097152, PROT_NONE) = 0mmap(0x7efe76e6c000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b6000) = 0x7efe76e6c000mmap(0x7efe76e72000, 16960, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7efe76e72000close(3) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77091000mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe7708f000arch_prctl(ARCH_SET_FS, 0x7efe7708f740) = 0mprotect(0x7efe76e6c000, 16384, PROT_READ) = 0mprotect(0x616000, 4096, PROT_READ) = 0mprotect(0x7efe77098000, 4096, PROT_READ) = 0munmap(0x7efe77092000, 19527) = 0brk(NULL) = 0x1e9c000brk(0x1ebd000) = 0x1ebd000brk(NULL) = 0x1ebd000open(&quot;/usr/lib/locale/locale-archive&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=106065056, ...&#125;) = 0mmap(NULL, 106065056, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe7058f000close(3) = 0open(&quot;/usr/share/locale/locale.alias&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=2502, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77096000read(3, &quot;# Locale name alias data base.\n#&quot;..., 4096) = 2502read(3, &quot;&quot;, 4096) = 0close(3) = 0munmap(0x7efe77096000, 4096) = 0open(&quot;/usr/share/locale/zh_CN.UTF-8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh_CN.utf8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh_CN/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=190751, ...&#125;) = 0mmap(NULL, 190751, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe77060000close(3) = 0open(&quot;/usr/share/locale/zh.UTF-8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh.utf8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/etc/mtab&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0444, st_size=0, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77096000read(3, &quot;rootfs / rootfs rw 0 0\nsysfs /sy&quot;..., 1024) = 1024read(3, &quot;ev,noexec,relatime,freezer 0 0\nc&quot;..., 1024) = 1024read(3, &quot;sd rw,relatime 0 0\n&quot;, 1024) = 19read(3, &quot;&quot;, 1024) = 0close(3) = 0munmap(0x7efe77096000, 4096) = 0open(&quot;/usr/lib64/gconv/gconv-modules.cache&quot;, O_RDONLY) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=26254, ...&#125;) = 0mmap(NULL, 26254, PROT_READ, MAP_SHARED, 3, 0) = 0x7efe77059000close(3) = 0stat(&quot;/&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0stat(&quot;/sys&quot;, &#123;st_mode=S_IFDIR|0555, st_size=0, ...&#125;) = 0stat(&quot;/proc&quot;, &#123;st_mode=S_IFDIR|0555, st_size=0, ...&#125;) = 0stat(&quot;/dev&quot;, &#123;st_mode=S_IFDIR|0755, st_size=3140, ...&#125;) = 0stat(&quot;/sys/kernel/security&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/dev/shm&quot;, &#123;st_mode=S_IFDIR|S_ISVTX|0777, st_size=40, ...&#125;) = 0stat(&quot;/dev/pts&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/run&quot;, &#123;st_mode=S_IFDIR|0755, st_size=740, ...&#125;) = 0stat(&quot;/sys/fs/cgroup&quot;, &#123;st_mode=S_IFDIR|0755, st_size=280, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/systemd&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/pstore&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/memory&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/cpu,cpuacct&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/net_cls&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/freezer&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/devices&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/blkio&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/perf_event&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/cpuset&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/hugetlb&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/kernel/config&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0stat(&quot;/proc/sys/fs/binfmt_misc&quot; df -h进程在”/proc/sys/fs/binfmt_misc”这个位置卡主了 3、启动另一个会话，重新挂在这个目录1systemctl restart proc-sys-fs-binfmt_misc.automount 4、strace df -h 跟踪的进程内容有新的输出，完整信息输出如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157execve(&quot;/usr/bin/df&quot;, [&quot;df&quot;, &quot;-h&quot;], [/* 24 vars */]) = 0brk(NULL) = 0x1e9c000mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77097000access(&quot;/etc/ld.so.preload&quot;, R_OK) = -1 ENOENT (No such file or directory)open(&quot;/etc/ld.so.cache&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=19527, ...&#125;) = 0mmap(NULL, 19527, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe77092000close(3) = 0open(&quot;/lib64/libc.so.6&quot;, O_RDONLY|O_CLOEXEC) = 3read(3, &quot;\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0 \34\2\0\0\0\0\0&quot;..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=2107816, ...&#125;) = 0mmap(NULL, 3932736, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7efe76ab6000mprotect(0x7efe76c6c000, 2097152, PROT_NONE) = 0mmap(0x7efe76e6c000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b6000) = 0x7efe76e6c000mmap(0x7efe76e72000, 16960, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7efe76e72000close(3) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77091000mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe7708f000arch_prctl(ARCH_SET_FS, 0x7efe7708f740) = 0mprotect(0x7efe76e6c000, 16384, PROT_READ) = 0mprotect(0x616000, 4096, PROT_READ) = 0mprotect(0x7efe77098000, 4096, PROT_READ) = 0munmap(0x7efe77092000, 19527) = 0brk(NULL) = 0x1e9c000brk(0x1ebd000) = 0x1ebd000brk(NULL) = 0x1ebd000open(&quot;/usr/lib/locale/locale-archive&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=106065056, ...&#125;) = 0mmap(NULL, 106065056, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe7058f000close(3) = 0open(&quot;/usr/share/locale/locale.alias&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=2502, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77096000read(3, &quot;# Locale name alias data base.\n#&quot;..., 4096) = 2502read(3, &quot;&quot;, 4096) = 0close(3) = 0munmap(0x7efe77096000, 4096) = 0open(&quot;/usr/share/locale/zh_CN.UTF-8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh_CN.utf8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh_CN/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=190751, ...&#125;) = 0mmap(NULL, 190751, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7efe77060000close(3) = 0open(&quot;/usr/share/locale/zh.UTF-8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh.utf8/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/usr/share/locale/zh/LC_MESSAGES/coreutils.mo&quot;, O_RDONLY) = -1 ENOENT (No such file or directory)open(&quot;/etc/mtab&quot;, O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0444, st_size=0, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77096000read(3, &quot;rootfs / rootfs rw 0 0\nsysfs /sy&quot;..., 1024) = 1024read(3, &quot;ev,noexec,relatime,freezer 0 0\nc&quot;..., 1024) = 1024read(3, &quot;sd rw,relatime 0 0\n&quot;, 1024) = 19read(3, &quot;&quot;, 1024) = 0close(3) = 0munmap(0x7efe77096000, 4096) = 0open(&quot;/usr/lib64/gconv/gconv-modules.cache&quot;, O_RDONLY) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=26254, ...&#125;) = 0mmap(NULL, 26254, PROT_READ, MAP_SHARED, 3, 0) = 0x7efe77059000close(3) = 0stat(&quot;/&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0stat(&quot;/sys&quot;, &#123;st_mode=S_IFDIR|0555, st_size=0, ...&#125;) = 0stat(&quot;/proc&quot;, &#123;st_mode=S_IFDIR|0555, st_size=0, ...&#125;) = 0stat(&quot;/dev&quot;, &#123;st_mode=S_IFDIR|0755, st_size=3140, ...&#125;) = 0stat(&quot;/sys/kernel/security&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/dev/shm&quot;, &#123;st_mode=S_IFDIR|S_ISVTX|0777, st_size=40, ...&#125;) = 0stat(&quot;/dev/pts&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/run&quot;, &#123;st_mode=S_IFDIR|0755, st_size=740, ...&#125;) = 0stat(&quot;/sys/fs/cgroup&quot;, &#123;st_mode=S_IFDIR|0755, st_size=280, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/systemd&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/pstore&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/memory&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/cpu,cpuacct&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/net_cls&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/freezer&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/devices&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/blkio&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/perf_event&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/cpuset&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/fs/cgroup/hugetlb&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/kernel/config&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0stat(&quot;/proc/sys/fs/binfmt_misc&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/dev/hugepages&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0stat(&quot;/sys/kernel/debug&quot;, &#123;st_mode=S_IFDIR|0700, st_size=0, ...&#125;) = 0stat(&quot;/dev/mqueue&quot;, &#123;st_mode=S_IFDIR|S_ISVTX|0777, st_size=40, ...&#125;) = 0stat(&quot;/boot&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0stat(&quot;/run/user/0&quot;, &#123;st_mode=S_IFDIR|0700, st_size=40, ...&#125;) = 0stat(&quot;/var/lib/nfs/rpc_pipefs&quot;, &#123;st_mode=S_IFDIR|0555, st_size=0, ...&#125;) = 0stat(&quot;/proc/fs/nfsd&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0uname(&#123;sysname=&quot;Linux&quot;, nodename=&quot;xkey-boss01-8035-184&quot;, ...&#125;) = 0statfs(&quot;/&quot;, &#123;f_type=0x58465342, f_bsize=4096, f_blocks=9293380, f_bfree=5378782, f_bavail=5378782, f_files=37191680, f_ffree=37150656, f_fsid=&#123;64768, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME&#125;) = 0stat(&quot;/&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0statfs(&quot;/dev&quot;, &#123;f_type=TMPFS_MAGIC, f_bsize=4096, f_blocks=494791, f_bfree=494791, f_bavail=494791, f_files=494791, f_ffree=494430, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID&#125;) = 0stat(&quot;/dev&quot;, &#123;st_mode=S_IFDIR|0755, st_size=3140, ...&#125;) = 0statfs(&quot;/sys/kernel/security&quot;, &#123;f_type=SECURITYFS_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/kernel/security&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/dev/shm&quot;, &#123;f_type=TMPFS_MAGIC, f_bsize=4096, f_blocks=497337, f_bfree=497337, f_bavail=497337, f_files=497337, f_ffree=497336, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV&#125;) = 0stat(&quot;/dev/shm&quot;, &#123;st_mode=S_IFDIR|S_ISVTX|0777, st_size=40, ...&#125;) = 0statfs(&quot;/run&quot;, &#123;f_type=TMPFS_MAGIC, f_bsize=4096, f_blocks=497337, f_bfree=458142, f_bavail=458142, f_files=497337, f_ffree=496689, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV&#125;) = 0stat(&quot;/run&quot;, &#123;st_mode=S_IFDIR|0755, st_size=740, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup&quot;, &#123;f_type=TMPFS_MAGIC, f_bsize=4096, f_blocks=497337, f_bfree=497337, f_bavail=497337, f_files=497337, f_ffree=497324, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RDONLY|ST_NOSUID|ST_NODEV|ST_NOEXEC&#125;) = 0stat(&quot;/sys/fs/cgroup&quot;, &#123;st_mode=S_IFDIR|0755, st_size=280, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/systemd&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/systemd&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/pstore&quot;, &#123;f_type=PSTOREFS_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/pstore&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/memory&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/memory&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/cpu,cpuacct&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/cpu,cpuacct&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/net_cls&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/net_cls&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/freezer&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/freezer&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/devices&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/devices&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/blkio&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/blkio&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/perf_event&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/perf_event&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/cpuset&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/cpuset&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/fs/cgroup/hugetlb&quot;, &#123;f_type=CGROUP_SUPER_MAGIC, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_NOEXEC|ST_RELATIME&#125;) = 0stat(&quot;/sys/fs/cgroup/hugetlb&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/sys/kernel/config&quot;, &#123;f_type=0x62656570, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME&#125;) = 0stat(&quot;/sys/kernel/config&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/dev/hugepages&quot;, &#123;f_type=HUGETLBFS_MAGIC, f_bsize=2097152, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=2097152, f_flags=ST_VALID|ST_RELATIME&#125;) = 0stat(&quot;/dev/hugepages&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0statfs(&quot;/boot&quot;, &#123;f_type=0x58465342, f_bsize=4096, f_blocks=127147, f_bfree=95769, f_bavail=95769, f_files=512000, f_ffree=511670, f_fsid=&#123;64513, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME&#125;) = 0stat(&quot;/boot&quot;, &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0statfs(&quot;/run/user/0&quot;, &#123;f_type=TMPFS_MAGIC, f_bsize=4096, f_blocks=99468, f_bfree=99468, f_bavail=99468, f_files=497337, f_ffree=497336, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOSUID|ST_NODEV|ST_RELATIME&#125;) = 0stat(&quot;/run/user/0&quot;, &#123;st_mode=S_IFDIR|0700, st_size=40, ...&#125;) = 0statfs(&quot;/proc/fs/nfsd&quot;, &#123;f_type=0x6e667364, f_bsize=4096, f_blocks=0, f_bfree=0, f_bavail=0, f_files=0, f_ffree=0, f_fsid=&#123;0, 0&#125;, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME&#125;) = 0stat(&quot;/proc/fs/nfsd&quot;, &#123;st_mode=S_IFDIR|0755, st_size=0, ...&#125;) = 0fstat(1, &#123;st_mode=S_IFCHR|0620, st_rdev=makedev(136, 7), ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7efe77096000write(1, &quot;\346\226\207\344\273\266\347\263\273\347\273\237 \345\256\271&quot;..., 70文件系统 容量 已用 可用 已用% 挂载点) = 70write(1, &quot;/dev/mapper/centos-root 36G &quot;..., 50/dev/mapper/centos-root 36G 15G 21G 43% /) = 50write(1, &quot;devtmpfs 1.9G &quot;..., 53devtmpfs 1.9G 0 1.9G 0% /dev) = 53write(1, &quot;tmpfs 1.9G &quot;..., 57tmpfs 1.9G 0 1.9G 0% /dev/shm) = 57write(1, &quot;tmpfs 1.9G 1&quot;..., 53tmpfs 1.9G 154M 1.8G 8% /run) = 53write(1, &quot;tmpfs 1.9G &quot;..., 63tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup) = 63write(1, &quot;/dev/vda1 497M 1&quot;..., 54/dev/vda1 497M 123M 375M 25% /boot) = 54write(1, &quot;tmpfs 389M &quot;..., 60tmpfs 389M 0 389M 0% /run/user/0) = 60close(1) = 0munmap(0x7efe77096000, 4096) = 0close(2) = 0exit_group(0) = ?+++ exited with 0 +++ 5、重新使用df -h命令，恢复正常。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] InnoDB：page_cleaner：1000ms intended loop took xxxms]]></title>
    <url>%2F2018%2F08%2F21%2FInnoDB-page_cleaner-1000ms%20intended%20loop%20took%20xxxms%2F</url>
    <content type="text"><![CDATA[1、在查看mysqllog日志的时候不经意间发现一条这个提示：1[Note] InnoDB: page_cleaner: 1000ms intended loop took 16111ms. The settings might not be optimal. (flushed=7 and evicted=0, during the time.) 造成该问题的主要原因：1234567page_cleaner_thread:脏页清理线程负责将脏页从内存写到磁盘。出现该问题的原因：上面提示的信息的含义是,有大量脏页需要刷新，理论上应该在1s内完成，但实际却用了16s的时间将脏页刷新到磁盘，它接受脏页的数量远远大于它每秒能够处理脏页的能力，因此为了避免该问题，可降低每秒循环期间搜索脏页的深度（innodb_lru_scan_depth）。如果数据库存在很多的buffer pool instance 将会引起更多的刷新工作，因此如果只是增大 buffer pool instances 而没有降低lru_scan_depth,很可能会引起性能瓶颈。如果只是临时对数据库进行大量导入操作造成的这类问题,可以忽略这个问题不需关注。如果数据库一直存在大量更新操作，快速创建大量的脏页，该问题一直存在需要关注。 下面是官方文档对lru_scan_depth参数的解释，中文为自己对官方文档的理解翻译，错误之处望大家指正。12345A setting smaller than the default is generally suitable for most workloads. A value that is much higher than necessary may impact performance. Only consider increasing the value if you have spare I/O capacity under a typical workload. Conversely, if a write-intensive workload saturates your I/O capacity, decrease the value, especially in the case of a large buffer pool.When tuning innodb_lru_scan_depth, start with a low value and configure the setting upward with the goal of rarely seeing zero free pages. Also, consider adjusting innodb_lru_scan_depth when changing the number of buffer pool instances, since innodb_lru_scan_depth * innodb_buffer_pool_instances defines the amount of work performed by the page cleaner thread each second.比默认值小适合于大多数工作负载，如果设置比默认值大可能会影响性能。只有当有额外的磁盘io容量的时候才考虑需不需要增加该值。相反，如果在写密集度负载已经使io容量饱和，需要降低该值，尤其是buffer pool的值设置特别大的时候。如果lru_scan_depth值特别低，而且存在0空闲页，可以考虑调高该值。如果调整buffer pool instances时，需要考虑是否调整innodb_lru_scan_depth大小，因为innodb_lru_scan_depth * innodb_buffer_pool_instances决定了每秒page cleaner thread处理的工作量。 2、解决方法1SET GLOBAL innodb_lru_scan_depth=256; 该参数默认只为1024。这只是数据库级别调整，出现该问题还需要查看服务器硬件问题，磁盘io是否达到瓶颈扥问题。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysql-mgr集群节点主节点与两个从节点网络异常，造成的集群异常问题]]></title>
    <url>%2F2018%2F08%2F20%2Fmysql-mgr%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E4%B8%BB%E8%8A%82%E7%82%B9%E4%B8%8E%E4%B8%A4%E4%B8%AA%E4%BB%8E%E8%8A%82%E7%82%B9%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%EF%BC%8C%E9%80%A0%E6%88%90%E7%9A%84%E9%9B%86%E7%BE%A4%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1、mysql-mgr集群节点主节点（A）与两个从节点网络异常，主节点（A）发生切换，从节点（B)切换为主，报错如下：1232018-08-20T05:38:16.071653Z 0 [Warning] Plugin group_replication reported: &apos;Member with address wallet-mysql-2:3306 has become unreachable.&apos;2018-08-20T05:38:16.071730Z 0 [Warning] Plugin group_replication reported: &apos;Member with address wallet-mysql-3:3306 has become unreachable.&apos;2018-08-20T05:38:16.071744Z 0 [ERROR] Plugin group_replication reported: &apos;This server is not able to reach a majority of members in the group. This server will now block all updates. The server will remain blocked until contact with the majority is restored. It is possible to use group_replication_force_members to force a new group membership.&apos; 2、对故障节点A操作，使其重新加入集群A节点：12mysql -u root -pstart group_replication; 查看报错日志：1234567891011121314152018-08-20T07:29:40.796952Z 12 [Note] Plugin group_replication reported: &apos;Terminating existing group replication donor connection and purging the corresponding logs.&apos;2018-08-20T07:29:40.803975Z 26 [Note] Error reading relay log event for channel &apos;group_replication_recovery&apos;: slave SQL thread was killed2018-08-20T07:29:40.855935Z 12 [Note] &apos;CHANGE MASTER TO FOR CHANNEL &apos;group_replication_recovery&apos; executed&apos;. Previous state master_host=&apos;wallet-mysql-2&apos;, master_port= 3306, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;. New state master_host=&apos;&lt;NULL&gt;&apos;, master_port= 0, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;.2018-08-20T07:29:40.906041Z 12 [Note] Plugin group_replication reported: &apos;Retrying group recovery connection with another donor. Attempt 4/10&apos;2018-08-20T07:29:40.949597Z 12 [Note] &apos;CHANGE MASTER TO FOR CHANNEL &apos;group_replication_recovery&apos; executed&apos;. Previous state master_host=&apos;&lt;NULL&gt;&apos;, master_port= 0, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;. New state master_host=&apos;wallet-mysql-3&apos;, master_port= 3306, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;.2018-08-20T07:29:41.001446Z 12 [Note] Plugin group_replication reported: &apos;Establishing connection to a group replication recovery donor 7dd813bf-8e3d-11e8-8d92-000d3aa1c31e at wallet-mysql-3 port: 3306.&apos;2018-08-20T07:29:41.001738Z 29 [Warning] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the &apos;START SLAVE Syntax&apos; in the MySQL Manual for more information.2018-08-20T07:29:41.005538Z 29 [Note] Slave I/O thread for channel &apos;group_replication_recovery&apos;: connected to master &apos;repl@wallet-mysql-3:3306&apos;,replication started in log &apos;FIRST&apos; at position 42018-08-20T07:29:41.016839Z 30 [Note] Slave SQL thread for channel &apos;group_replication_recovery&apos; initialized, starting replication in log &apos;FIRST&apos; at position 0, relay log &apos;./relay-log-group_replication_recovery.000001&apos; position: 42018-08-20T07:29:41.028408Z 29 [ERROR] Error reading packet from server for channel &apos;group_replication_recovery&apos;: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. (server_errno=1236)2018-08-20T07:29:41.028442Z 29 [ERROR] Slave I/O for channel &apos;group_replication_recovery&apos;: Got fatal error 1236 from master when reading data from binary log: &apos;The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires.&apos;, Error_code: 12362018-08-20T07:29:41.028449Z 29 [Note] Slave I/O thread exiting for channel &apos;group_replication_recovery&apos;, read up to log &apos;FIRST&apos;, position 42018-08-20T07:29:41.028493Z 12 [Note] Plugin group_replication reported: &apos;Terminating existing group replication donor connection and purging the corresponding logs.&apos;2018-08-20T07:29:41.028790Z 30 [Note] Error reading relay log event for channel &apos;group_replication_recovery&apos;: slave SQL thread was killed2018-08-20T07:29:41.085012Z 12 [Note] &apos;CHANGE MASTER TO FOR CHANNEL &apos;group_replication_recovery&apos; executed&apos;. Previous state master_host=&apos;wallet-mysql-3&apos;, master_port= 3306, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;. New state master_host=&apos;&lt;NULL&gt;&apos;, master_port= 0, master_log_file=&apos;&apos;, master_log_pos= 4, master_bind=&apos;&apos;. 出现该问题的原因是现在的新的主节点B，已经清除了binglog,A节点需要恢复的日志已经找不到了，因此需要对A进行数据恢复。 3、在B节点mysqldump一份最新数据，命令如下：1/data/mysql/bin/mysqldump --all-databases --set-gtid-purged=ON --single-transaction -uroot -p***** &gt; /data/backup/all.sql 4、将dump的数据库拷贝到A节点，对节点A进行恢复：1mysql -u root -p******* &lt; /data/backup/all.sql 执行提示报错12mysql: [Warning] Using a password on the command line interface can be insecure.ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty. 解决方法：12345678910提示只有@@GLOBAL.GTID_EXECUTED为空是，才能设置@@GLOBAL.GTID_PURGED的值，清空GLOBAL.GTID_EXECUTED的值root@db 07:53: [(none)]&gt; reset master;ERROR 3190 (HY000): RESET MASTER is not allowed because Group Replication is running.root@db 07:53: [(none)]&gt; stop group_replication;Query OK, 0 rows affected (1.01 sec)root@db 07:53: [(none)]&gt; reset master;Query OK, 0 rows affected (0.27 sec)如果数据库为只读的状态还需要将数据库改为读写模式：root@db 07:54: [performance_schema]&gt; set global read_only=0;Query OK, 0 rows affected (0.00 sec) 5、重新恢复数据12mysql -u root -p******* &lt; /data/backup/all.sqlmysql: [Warning] Using a password on the command line interface can be insecure. 恢复完成 6、重新将该节点加入集群1234567891011121314151617181920mysql -u root -proot@db 07:56: [performance_schema]&gt; select * from replication_group_members;+---------------------------+-----------+-------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+-----------+-------------+-------------+--------------+| group_replication_applier | | | NULL | OFFLINE |+---------------------------+-----------+-------------+-------------+--------------+1 row in set (0.00 sec)root@db 07:56: [performance_schema]&gt; start group_replication;Query OK, 0 rows affected, 1 warning (3.03 sec)root@db 07:57: [performance_schema]&gt; select * from replication_group_members;+---------------------------+--------------------------------------+----------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+----------------+-------------+--------------+| group_replication_applier | *** | wallet-mysql-2 | 3306 | ONLINE || group_replication_applier | *** | wallet-mysql-1 | 3306 | RECOVERING || group_replication_applier | *** | wallet-mysql-3 | 3306 | ONLINE |+---------------------------+--------------------------------------+----------------+-------------+--------------+3 rows in set (0.00 sec) 此时节点A正在与主节点同步数据，待同步完成之后再查看及节点之间的信息：123456789root@db 07:57: [performance_schema]&gt; select * from replication_group_members;+---------------------------+--------------------------------------+----------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+----------------+-------------+--------------+| group_replication_applier | *** | wallet-mysql-2 | 3306 | ONLINE || group_replication_applier | *** | wallet-mysql-1 | 3306 | ONLINE || group_replication_applier | *** | wallet-mysql-3 | 3306 | ONLINE |+---------------------------+--------------------------------------+----------------+-------------+--------------+3 rows in set (0.00 sec) 此时集群恢复完成。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Zabbix] zabbix监控redis数据库]]></title>
    <url>%2F2018%2F08%2F17%2Fzabbix%E7%9B%91%E6%8E%A7redis%2F</url>
    <content type="text"><![CDATA[1、编写定期收集redis信息脚本，并指定到对应目录cat /usr/local/zabbix/script/redis_get_data.sh1234567891011121314151617#!/bin/bash#配置文件路径dbconfigfile=/data/redis/etc/redis.conf#主机ip地址dbhost=`cat $&#123;dbconfigfile&#125; |grep bind|awk '&#123;print $2&#125;'`#redis启动端口dbport=`cat $&#123;dbconfigfile&#125; |grep port|awk '&#123;print $2&#125;'`#数据库命令路径dbcmdpath=/data/redis/src#数据库密码dbpass=`cat $&#123;dbconfigfile&#125; |grep requirepass|awk '&#123;print $2&#125;'`#指定生成的log路径dblogpath=/tmp/redis.log#如果有没密码，使用以下命令#$&#123;dbcmdpath&#125;/redis-cli -h $&#123;dbhost&#125; -a $&#123;dbpass&#125; -p $&#123;dbport&#125; 'info' &gt; $&#123;dblogpath&#125;#如果没有密码，使用以下命令$&#123;dbcmdpath&#125;/redis-cli -h $&#123;dbhost&#125; -p $&#123;dbport&#125; 'info' &gt; $&#123;dblogpath&#125; 修改redis配置文件目录，生成的log目录，修改完成之后授权脚本执行权限：1chmod +x /usr/local/zabbix/script/redis_get_data.sh 2、将脚本添加到定时任务，每分钟执行一次crontab -l1* * * * * sh /usr/local/zabbix/script/redis_get_data.sh 3、编写zabbix监控项文件,通过/usr/local/zabbix/script/redis_get_data.sh脚本生成的log文件，根据关键字过滤，获取对应监控的数值vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/redis_monitor_parameter.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#数据库进程是否存在UserParameter=redis_exist[*],ps -ef|grep redis-server|grep -v grep|wc -l#客户端连接数，包括从库的连接UserParameter=connected_clients[*],cat /tmp/redis.log |grep &apos;connected_clients&apos; |cut -d&apos;:&apos; -f2#当前客户端最长输出列表UserParameter=client_longest_output_list[*],cat /tmp/redis.log |grep client_longest_output_list |cut -d&apos;:&apos; -f2#当前客户端最大输入缓冲区UserParameter=client_biggest_input_buf[*],cat /tmp/redis.log |grep client_biggest_input_buf |cut -d&apos;:&apos; -f2#阻塞会话数UserParameter=blocked_clients[*],cat /tmp/redis.log |grep blocked_clients |cut -d&apos;:&apos; -f2#redis通过分配器分配的总内存UserParameter=used_memory[*],cat /tmp/redis.log |grep used_memory |cut -d&apos;:&apos; -f2|head -1#操作系统通过top和ps命令查看到redis分配的内存UserParameter=used_memory_rss[*],cat /tmp/redis.log |grep used_memory_rss |cut -d&apos;:&apos; -f2|head -1#redis消耗内存的峰值UserParameter=used_memory_peak[*],cat /tmp/redis.log |grep used_memory_peak |cut -d&apos;:&apos; -f2|head -1#系统为管理内部数据架构造成的所有内存开销UserParameter=used_memory_overhead[*],cat /tmp/redis.log |grep used_memory_overhead |cut -d&apos;:&apos; -f2|head -1#redis启动初始化消耗的内存UserParameter=used_memory_startup[*],cat /tmp/redis.log |grep used_memory_startup |cut -d&apos;:&apos; -f2|head -1#数据集的大小（used_memory减去used_memory_overhead）UserParameter=used_memory_dataset[*],cat /tmp/redis.log |grep used_memory_dataset |cut -d&apos;:&apos; -f2|head -1#数据集内存占净内存的百分比（used_memory_dataset/(used_memory-used_memory_startup))UserParameter=used_memory_dataset_perc[*],cat /tmp/redis.log |grep used_memory_dataset_perc |cut -d&apos;:&apos; -f2|head -1|cut -d&apos;%&apos; -f1#lua引擎使用的内存UserParameter=used_memory_lua[*],cat /tmp/redis.log |grep used_memory_lua |cut -d&apos;:&apos; -f2|head -1#系统配置文件配置的内存UserParameter=maxmemory[*],cat /tmp/redis.log |grep maxmemory |cut -d&apos;:&apos; -f2|head -1#内存碎片率（需要重点关注）远大于1过高说明内存碎片化严重，原小于1过低说明有大量内存交换，建议增加内存。UserParameter=mem_fragmentation_ratio[*],cat /tmp/redis.log |grep mem_fragmentation_ratio |cut -d&apos;:&apos; -f2|head -1#自上次转存以来redis发生的更改数UserParameter=rdb_changes_since_last_save[*],cat /tmp/redis.log |grep rdb_changes_since_last_save |cut -d&apos;:&apos; -f2|head -1#服务端接受的总连接数UserParameter=total_connections_received[*],cat /tmp/redis.log |grep total_connections_received |cut -d&apos;:&apos; -f2|head -1#服务端处理命令总数UserParameter=total_commands_processed[*],cat /tmp/redis.log |grep total_commands_processed |cut -d&apos;:&apos; -f2|head -1#服务端每秒处理命令数UserParameter=instantaneous_ops_per_sec[*],cat /tmp/redis.log |grep instantaneous_ops_per_sec |cut -d&apos;:&apos; -f2|head -1#网络读取的总流量UserParameter=total_net_input_bytes[*],cat /tmp/redis.log |grep total_net_input_bytes |cut -d&apos;:&apos; -f2|head -1#网络写入的总流量UserParameter=total_net_output_bytes[*],cat /tmp/redis.log |grep total_net_output_bytes |cut -d&apos;:&apos; -f2|head -1#每秒网络读的流量UserParameter=instantaneous_input_kbps[*],cat /tmp/redis.log |grep instantaneous_input_kbps |cut -d&apos;:&apos; -f2|head -1#每秒网络写的流量UserParameter=instantaneous_output_kbps[*],cat /tmp/redis.log |grep instantaneous_output_kbps |cut -d&apos;:&apos; -f2|head -1#因最大连接数达到上限，而被拒绝的连接数，maxclient默认值为10000UserParameter=rejected_connections[*],cat /tmp/redis.log |grep rejected_connections |cut -d&apos;:&apos; -f2|head -1#键值到期总数UserParameter=expired_keys[*],cat /tmp/redis.log |grep expired_keys |cut -d&apos;:&apos; -f2|head -1#因maxmemory限制，被驱逐的键值UserParameter=evicted_keys[*],cat /tmp/redis.log |grep evicted_keys |cut -d&apos;:&apos; -f2|head -1#在主字典里面键值匹配成功的次数UserParameter=keyspace_hits[*],cat /tmp/redis.log |grep keyspace_hits |cut -d&apos;:&apos; -f2|head -1#在主字典里面键值匹配失败的次数UserParameter=keyspace_misses[*],cat /tmp/redis.log |grep keyspace_misses |cut -d&apos;:&apos; -f2|head -1#db0数据库键值的数量UserParameter=db0_keys[*], cat /tmp/redis.log |grep db0 |cat /tmp/redis.log |grep db0|cut -d &apos;,&apos; -f1|cut -d &apos;=&apos; -f2#db0数据库键值过期的数量UserParameter=db0_keys_expired[*],cat /tmp/redis.log |cat /tmp/redis.log |grep db0|cut -d &apos;,&apos; -f2|cut -d &apos;=&apos; -f2 4、修改/usr/local/zabbix/etc/zabbix_agentd.conf配置文件,添加该行参数：1Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/ 添加完成之后，需要重启zabbix_agent客户端1/etc/init.d/zabbix_agentd restart 5、通过zabbix-web控制台，自定义一个模板，新建监控项、触发器、图形等内容，下面链接是我创建的比较简单的redis模板，上传到百度云，仅供参考，点击下载]]></content>
      <tags>
        <tag>zabbix</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[linux] suse_11_sp4安装samba-server]]></title>
    <url>%2F2018%2F08%2F17%2Fsamba%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[0、当前系统版本12cat /etc/issueWelcome to SUSE Linux Enterprise Server 11 SP4 (x86_64) - Kernel \r (\l). 1、查看samba是否安装12localhost:~ # rpm -q sambasamba-3.6.3-0.58.1 如果没有安装，使用以下命令安装：1localhost:~ # zypper install samba 2、新建共享目录1localhost:~ # mkdir -p /data/share 3、开始配置共享目录yast进入控制台,network services-samba server第一次启用samba server会做一些初始化，操作如下（也可根据自己需求自定义）：初始化完成之后，再一次进入samba server,会显示如下：点击add,开始新增共享目录修改完成之后保存，会显示新的share目录 4、添加smbuser系统用户1234567localhost:~ # useradd smbuserlocalhost:~ # passwd smbuserChanging password for smbuser.New Password: Bad password: too simpleReenter New Password: Password changed. 5、为samba服务添加访问用户，设置访问用的密码：1234localhost:~ # smbpasswd -a smbuserNew SMB password:Retype new SMB password:Added user smbuser. 6、修改共享目录权限12chown smbuser /data/sharechmod 777 /data/share **如果不修改目录权限，访问预览都是正常的，但是没有写权限，创建目录会报错 7、修改配置配置文件,添加读写权限vim /etc/samba/smb.conf12345678[share] comment = share inherit acls = Yes path = /data/share read only = No Valid users =smbuser Writable = Yes Browsable = Yes 8、重启samba服务器/etc/rc.d/smb restart 9、suse默认防火墙是开启的，客户端要访问samba,需要开启139和445端口vim /etc/sysconfig/SuSEfirewall21FW_SERVICES_EXT_TCP=&quot;22 1521 139 445&quot; 重新启动防火墙1rcSuSEfirewall2 restart 10、windows10之后微软默认已放弃安装smbv1客户端，使用windows访问会报如下错误：因此修改sambaserver服务器端的协议，启用smbv2协议vim /etc/samba/smb.conf12345[global]min protocol = SMB2max protocol = SMB2client min protocol = SMB2client max protocol = SMB2 重启samba服务器1/etc/rc.d/smb restart 11、在sambaserver本地服务器测试的时候，哪怕指定了smb2协议，也会报如下错误1234567smbclient -U smbuser //10.0.30.180/share -m smb2Unrecognised protocol level smb2WARNING: Ignoring invalid value &apos;SMB3&apos; for parameter &apos;max protocol&apos;Unknown parameter encountered: &quot;client min protocol&quot;Ignoring unknown parameter &quot;client min protocol&quot;Unknown parameter encountered: &quot;client max protocol&quot;Ignoring unknown parameter &quot;client max protocol&quot; 该问题为suse 11版本的问题，默认只支持smbv1协议，suse12版本之后才开始支持smbv2.]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysql lock table && unlock tables实验]]></title>
    <url>%2F2018%2F08%2F17%2Fmysql%20lock%20table%20%26%26%20unlock%20tables%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[0、mysql版本1234567root@db 04:12: [aaaa]&gt; select @@version;+------------+| @@version |+------------+| 5.7.22-log |+------------+1 row in set (0.00 sec) 1、创建实验表，内容如下：123456789101112131415161718192021222324252627root@db 15:11: [aaaa]&gt; show tables;+----------------+| Tables_in_aaaa |+----------------+| aaa || bbb |+----------------+2 rows in set (0.00 sec)root@db 15:15: [aaaa]&gt; select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 15:15: [aaaa]&gt; select * from bbb;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 |+----+------+-------------+3 rows in set (0.00 sec) 2、开启两个会话，session1、session2,对表aaa进行read表锁session11234567891011121314151617root@db 15:16: [aaaa]&gt; lock table aaa read;Query OK, 0 rows affected (0.00 sec)root@db 15:17: [aaaa]&gt; select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 15:17: [aaaa]&gt; select * from bbb;ERROR 1100 (HY000): Table &apos;bbb&apos; was not locked with LOCK TABLESroot@db 15:17: [aaaa]&gt; root@db 15:18: [aaaa]&gt; update aaa set name=&apos;e&apos; where id=1;ERROR 1099 (HY000): Table &apos;aaa&apos; was locked with a READ lock and can&apos;t be updated session 212345678910111213141516171819root@db 15:18: [aaaa]&gt; select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 15:18: [aaaa]&gt; update aaa set name=&apos;e&apos; where id=1;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionroot@db 15:20: [aaaa]&gt; show OPEN TABLES where In_use &gt; 0;+----------+-------+--------+-------------+| Database | Table | In_use | Name_locked |+----------+-------+--------+-------------+| aaaa | aaa | 1 | 0 |+----------+-------+--------+-------------+1 row in set (0.00 sec) session 112root@db 15:21: [aaaa]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 结论：在session1对表aaa进行read锁表，session1只能对表aaa进行读操作，对其他表没有任何操作权限，session2对表aaa有读权限，没有写权限。 3、开启两个会话，session1、session2,对表aaa进行write表锁session 112345678910111213141516171819root@db 15:21: [aaaa]&gt; lock table aaa write;Query OK, 0 rows affected (0.00 sec)root@db 15:26: [aaaa]&gt; select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 15:26: [aaaa]&gt; select * from bbb;ERROR 1100 (HY000): Table &apos;bbb&apos; was not locked with LOCK TABLESroot@db 15:27: [aaaa]&gt; update aaa set name=&apos;e&apos; where id=1;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0root@db 15:29: [aaaa]&gt; update bbb set name=&apos;e&apos; where id=1;ERROR 1100 (HY000): Table &apos;bbb&apos; was not locked with LOCK TABLES session 21234root@db 15:20: [aaaa]&gt; select * from aaa;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionroot@db 15:28: [aaaa]&gt; update aaa set name=&apos;e&apos; where id=1;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction session 112root@db 15:31: [aaaa]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 结论：在session1对表aaa进行write锁表，session1对表aaa有读写权限，对其他表没有任何操作权限，session2对表aaa即没有读权限，又没有写权限。 4、开启两个会话，session1、session2,对表aaa进行write&amp;read表锁session112345678910111213141516171819202122232425262728293031323334root@db 15:32: [aaaa]&gt; lock table aaa write , aaa as t1 read;Query OK, 0 rows affected (0.00 sec)root@db 15:32root@db 04:01: [aaaa]&gt; select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | e | 11111111111 || 2 | e | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 04:01: [aaaa]&gt; select * from aaa as t1;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | e | 11111111111 || 2 | e | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 |+----+------+-------------+4 rows in set (0.00 sec)root@db 04:02: [aaaa]&gt; update aaa as t1 set name=&apos;e&apos; where id =1;ERROR 1099 (HY000): Table &apos;t1&apos; was locked with a READ lock and can&apos;t be updatedroot@db 04:04: [aaaa]&gt; update aaa set name=&apos;e&apos; where id =1;Query OK, 0 rows affected (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 0root@db 04:04: [aaaa]&gt; insert into aaa select * from aaa;ERROR 1100 (HY000): Table &apos;aaa&apos; was not locked with LOCK TABLESroot@db 04:04: [aaaa]&gt; insert into aaa select * from aaa as t1;ERROR 1062 (23000): Duplicate entry &apos;1&apos; for key &apos;PRIMARY&apos; session21234root@db 04:05: [aaaa]&gt; select * from aaa;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionroot@db 04:06: [aaaa]&gt; update aaa set name=&apos;e&apos; where id=2;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction session112root@db 04:07: [aaaa]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 结论：session1对表aaa同时进行read，write锁，需要使用别名。对表进行select,update操作正常，如果使用insert into aaa select * from aaa as t1;需要加上别名。session 2对表aaa即没有读权限，又没有写权限。 5、对表aaa进行read表锁，并使用别名session 112345678910111213141516root@db 03:47: [aaaa]&gt; LOCK TABLE aaa AS t1 READ;Query OK, 0 rows affected (0.00 sec)root@db 03:47: [aaaa]&gt; select * from aaa;ERROR 1100 (HY000): Table &apos;aaa&apos; was not locked with LOCK TABLESroot@db 03:47: [aaaa]&gt; select * from aaa as t1;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | e | 11111111111 || 2 | e | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 || 5 | f | 5555555 |+----+------+-------------+5 rows in set (0.00 sec) session 21234567891011 select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | e | 11111111111 || 2 | e | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 || 5 | f | 5555555 |+----+------+-------------+5 rows in set (0.00 sec) session 112root@db 03:48: [aaaa]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 结论：session 1对表aaa加别名read表锁，session1查询需要使用别名，直接查询无效，session2对表aaa有读权限，无写权限 6、对表aaa使用write表锁，并添加别名session 11234567891011121314151617181920212223root@db 03:51: [aaaa]&gt; LOCK TABLE aaa AS t1 write;Query OK, 0 rows affected (0.00 sec)root@db 03:53: [aaaa]&gt; root@db 03:53: [aaaa]&gt; select * from aaa;ERROR 1100 (HY000): Table &apos;aaa&apos; was not locked with LOCK TABLESroot@db 03:53: [aaaa]&gt; select * from aaa as t1;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | e | 11111111111 || 2 | e | 22222222222 || 3 | c | 33333333333 || 4 | d | 44444444 || 5 | f | 5555555 |+----+------+-------------+5 rows in set (0.00 sec)root@db 03:53: [aaaa]&gt; update aaa set name=&apos;e&apos; where id =1;ERROR 1100 (HY000): Table &apos;aaa&apos; was not locked with LOCK TABLESroot@db 03:54: [aaaa]&gt; update aaa as t1 set name=&apos;e&apos; where id =1;Query OK, 0 rows affected (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 0 session 212root@db 03:55: [aaaa]&gt; select * from aaa;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction session 112root@db 03:55: [aaaa]&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 结论：session 1对表aaa加别名write表锁，session1查询和更改需要使用别名，直接查询和更改无效，session2对表aaa无读权限，无写权限 ##7、额外提示：1LOCK TABLES或者UNLOCK TABLES，当应用于分区表时，始终锁定或解锁整个表; 这些语句不支持分区锁定修剪]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Zabbix] zabbix监控mongodb数据库]]></title>
    <url>%2F2018%2F08%2F15%2Fzabbix%E7%9B%91%E6%8E%A7mongodb%2F</url>
    <content type="text"><![CDATA[1、创建监控脚本，用于连接mongodb数据库，可根据自身数据库配置修改该脚本mkdir -p /usr/local/zabbix/scriptvim /usr/local/zabbix/script/zabbix_monitor_mongodb.sh123456789101112#!/bin/bash#mongodb管理员用户authuser=admin1#mongodb管理员密码authpass=admin123#Mongodb指定验证数据库authdb=admin#mongodb指定端口dbport=30000#mongodb安装路径dbpath=/data/mongodb/bin$&#123;dbpath&#125;/mongo --port $&#123;dbport&#125; -u $&#123;authuser&#125; -p $&#123;authpass&#125; --authenticationDatabase $&#123;authdb&#125; 授权脚本执行权限1chmod +x /usr/local/zabbix/script/zabbix_monitor_mongodb.sh 2、修改zabbix监控项脚本，用于获取mongodb参数vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/zabbix_mongodb.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#当前连接数，包括当前的shell会话，副本集成员连接，mongos实例连接#(4.0version)connections.current[*],echo &quot;db.serverStatus().connections.current&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=connections.current[*],echo &quot;db.serverStatus().connections.current&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#当前可用的连接数，数据库上的连接负载的值#(4.0version)connections.available[*],echo &quot;db.serverStatus().connections.available&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=connections.available[*],echo &quot;db.serverStatus().connections.available&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#服务器所有的连接，包括已经关闭的连接#(4.0version)connections.totalCreated[*],echo &quot;db.serverStatus().connections.totalCreated&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=connections.totalCreated[*],echo &quot;db.serverStatus().connections.totalCreated&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p|cut -d &apos;(&apos; -f2|cut -d &apos;)&apos; -f1#因锁而造成排队等待的总数#(4.0version)UserParameter=globalLock.currentQueue.total[*],echo &quot;db.serverStatus().globalLock.currentQueue.total&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=globalLock.currentQueue.total[*],echo &quot;db.serverStatus().globalLock.currentQueue.total&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#因读锁而造成排队等待的数量#(4.0version)UserParameter=globalLock.currentQueue.readers[*],echo &quot;db.serverStatus().globalLock.currentQueue.readers&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=globalLock.currentQueue.readers[*],echo &quot;db.serverStatus().globalLock.currentQueue.readers&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#因写锁而造成排队等待的数量#(4.0version)UserParameter=globalLock.currentQueue.writers[*],echo &quot;db.serverStatus().globalLock.currentQueue.writers&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#3.0versionUserParameter=globalLock.currentQueue.writers[*],echo &quot;db.serverStatus().globalLock.currentQueue.writers&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#当前数据库进程占用内存情况#(4.0version)mem.resident[*],echo &quot;db.serverStatus().mem.resident&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=mem.resident[*],echo &quot;db.serverStatus().mem.resident&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#当前数据库进程占用虚拟内存的大小#(4.0version)mem.virtual[*],echo &quot;db.serverStatus().mem.virtual&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=mem.virtual[*],echo &quot;db.serverStatus().mem.virtual&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#流入mongodb数据库的总量#(4.0version)network.bytesIn[*],echo &quot;db.serverStatus().network.bytesIn&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh| grep NumberLong |cut -d &apos;(&apos; -f2|cut -d &apos;)&apos; -f1#3.0versionUserParameter=network.bytesIn[*],echo &quot;db.serverStatus().network.bytesIn&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#数据库流出总量#(4.0version)network.bytesOut[*],echo &quot;db.serverStatus().network.bytesOut&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh| grep NumberLong |cut -d &apos;(&apos; -f2|cut -d &apos;)&apos; -f1|cut -d &apos;&quot;&apos; -f2|cut -d &apos;&quot;&apos; -f1#3.0versionUserParameter=network.bytesOut[*],echo &quot;db.serverStatus().network.bytesOut&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#数据库总请求数#(4.0version)network.numRequests[*],echo &quot;db.serverStatus().network.numRequests&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh| grep NumberLong |cut -d &apos;(&apos; -f2|cut -d &apos;)&apos; -f1#3.0versionUserParameter=network.numRequests[*],echo &quot;db.serverStatus().network.numRequests&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#当前副本集状态，为1代表为主节点，为2代表为从节点#(4.0version)rs.status.myState[*],echo &quot;rs.status().myState&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=rs.status.myState[*],echo &quot;rs.status().myState&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p#页错误总数，当数据库性能不佳、内存限制、或者数据库较大会导致该值增加#(4.0version)extra_info.page_faults[*],echo &quot;db.serverStatus().extra_info.page_faults&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 4p#3.0versionUserParameter=extra_info.page_faults[*],echo &quot;db.serverStatus().extra_info.page_faults&quot;|sh /usr/local/zabbix/script/zabbix_monitor_mongodb.sh|sed -n 3p 3、修改zabbix-agent配置文件，添加zabbix_agentd.conf.d目录，用于加载该目录下文件vim /usr/local/zabbix/etc/zabbix_agentd.conf1Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/ 4、重新启动agent客户端1/etc/init.d/zabbix_agentd restart 5、通过zabbix-web端，添加配置模板，参考模板，点击下载]]></content>
      <tags>
        <tag>mongodb</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Zabbix] zabbix监控mysql数据库]]></title>
    <url>%2F2018%2F08%2F14%2Fzabbix%E7%9B%91%E6%8E%A7mysql%2F</url>
    <content type="text"><![CDATA[1、编写定期收集mysql信息脚本，并指定到对应目录cat /usr/local/zabbix/script/mysql_monitor.sh12345678910111213141516171819#!/bin/bashdbpath='/data/mysql/bin/mysql'#mysql的用户dbuser='root'#mysql的密码dbpass='123456'#mysql的端口dbport='3306'#mysql的socket文件dbsocket='/data/mysql/tmp/mysql.sock'#mysql-status日志路径dbstatuspath=/tmp/mysql_status_monitor.log#mysql-engine-status日志路径dbenginestatuspath=/tmp/mysql_engine_innodb_status.log#查询mysql-status信息$&#123;dbpath&#125; -u$&#123;dbuser&#125; -p$&#123;dbpass&#125; -S$&#123;dbsocket&#125; -P$&#123;dbport&#125; -BNe "show global status;" &gt; $&#123;dbstatuspath&#125;#查询mysql-engine-innodb信息$&#123;dbpath&#125; -u$&#123;dbuser&#125; -p$&#123;dbpass&#125; -S$&#123;dbsocket&#125; -P$&#123;dbport&#125; -BNe "show engine innodb status\G" &gt; $&#123;dbenginestatuspath&#125; 根据自己的数据库配置，修改相应的参数，修改完成之后授权脚本执行权限：1chmod +x /usr/local/zabbix/script/mysql_monitor.sh 2、将脚本添加到定时任务，每分钟执行一次crontab -l1* * * * * sh /usr/local/zabbix/script/mysql_monitor.sh 3、编写获取数据脚本，对定时生成的log文件进行信息筛选cat /usr/local/zabbix/script/mysql_get_data.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#!/bin/bashdbpath='/data/mysql/bin/mysql'#mysql的用户dbuser='root'#mysql的密码dbpass='123456'#mysql的端口dbport='3306'#mysql的socket文件dbsocket='/data/mysql/tmp/mysql.sock'#mysql-status日志路径dbstatuspath=/tmp/mysql_status_monitor.log#mysql-engine-status日志路径dbenginestatuspath=/tmp/mysql_engine_innodb_status.logcase $1 in nodecount) #查询集群节点存活状态 nodecount=`export MYSQL_PWD=$&#123;dbpass&#125;;$&#123;dbpath&#125; -u$&#123;dbuser&#125; -S$&#123;dbsocket&#125; -P$&#123;dbport&#125; -BNe "select count(*) from performance_schema.replication_group_members where MEMBER_STATE='ONLINE'"` echo $&#123;nodecount&#125; ;; uptime) cat /tmp/mysql_status_monitor.log | awk '/Uptime/ &#123;print $2&#125;' |head -1 ;; com_select) cat /tmp/mysql_status_monitor.log | awk '/Com_select/ &#123;print $2&#125;' ;; com_insert) cat /tmp/mysql_status_monitor.log | awk '/Com_insert/ &#123;print $2&#125;'|head -1 ;; com_update) cat /tmp/mysql_status_monitor.log | awk '/Com_update/ &#123;print $2&#125;'|head -1 ;; com_delete) cat /tmp/mysql_status_monitor.log | awk '/Com_delete/ &#123;print $2&#125;'|head -1 ;; connections) cat /tmp/mysql_status_monitor.log | awk '/Connections/ &#123;print $2&#125;'|head -1 ;; thread_cached) cat /tmp/mysql_status_monitor.log | awk '/Threads_cached/ &#123;print $2&#125;' ;; threads_connected) cat /tmp/mysql_status_monitor.log | awk '/Threads_connected/ &#123;print $2&#125;' ;; thread_created) cat /tmp/mysql_status_monitor.log | awk '/Threads_created/ &#123;print $2&#125;' ;; Threads_running) cat /tmp/mysql_status_monitor.log | awk '/Threads_running/ &#123;print $2&#125;' ;; table_locks_immediate) cat /tmp/mysql_status_monitor.log | awk '/Table_locks_immediate/ &#123;print $2&#125;' ;; table_locks_waited) cat /tmp/mysql_status_monitor.log | awk '/Table_locks_waited/ &#123;print $2&#125;' ;; slow_launch_threads) cat /tmp/mysql_status_monitor.log | awk '/Slow_launch_threads/ &#123;print $2&#125;' ;; slow_queries) cat /tmp/mysql_status_monitor.log | awk '/Slow_queries/ &#123;print $2&#125;' ;; qps) uptime=`cat /tmp/mysql_status_monitor.log | awk '/Uptime/ &#123;print $2&#125;' |head -1` questions=`cat /tmp/mysql_status_monitor.log | awk '/Questions/ &#123;print $2&#125;'` echo $(printf "%.2f" `echo "scale=2;$&#123;questions&#125;/$&#123;uptime&#125;"|bc`) ;; tps) uptime=`cat /tmp/mysql_status_monitor.log | awk '/Uptime/ &#123;print $2&#125;' |head -1` com_commit=`cat /tmp/mysql_status_monitor.log | awk '/Com_commit/ &#123;print $2&#125;'` com_rollback=`cat /tmp/mysql_status_monitor.log | awk '/Com_rollback/ &#123;print $2&#125;'|head -1` com_sum=$(($&#123;com_commit&#125;+$&#123;com_rollback&#125;)) echo $(printf "%.2f" `echo "scale=2;$&#123;com_sum&#125;/$&#123;uptime&#125;"|bc`) ;; innodb_buffer_read_hits) innodb_buffer_pool_reads=`cat /tmp/mysql_status_monitor.log | awk '/Innodb_buffer_pool_reads/ &#123;print $2&#125;'|head -1` innodb_buffer_pool_read_requests=`cat /tmp/mysql_status_monitor.log | awk '/Innodb_buffer_pool_read_requests/ &#123;print $2&#125;'|head -1` innodb_buffer_read_diff=$(($&#123;innodb_buffer_pool_read_requests&#125;-$&#123;innodb_buffer_pool_reads&#125;)) echo $(printf "%.2f" `echo "scale=2;$&#123;innodb_buffer_read_diff&#125;/$&#123;innodb_buffer_pool_read_requests&#125;"|bc`) ;; table_cache_hit) cat /tmp/mysql_status_monitor.log | awk '/Opened_tables/ &#123;print $2&#125;' ;; thread_cache_hits) thread_created=`cat /tmp/mysql_status_monitor.log | awk '/Threads_created/ &#123;print $2&#125;'` connections=`cat /tmp/mysql_status_monitor.log | awk '/Connections/ &#123;print $2&#125;'|head -1` thread_cache_diff=$(($&#123;connections&#125;-$&#123;thread_created&#125;)) echo $(printf "%.2f" `echo "scale=2;$&#123;thread_cache_diff&#125;/$&#123;connections&#125;"|bc`) ;; create_tmp_tables_hits) created_tmp_tables=`cat /tmp/mysql_status_monitor.log | awk '/Created_tmp_tables/ &#123;print $2&#125;'` created_tmp_disk_tables=`cat /tmp/mysql_status_monitor.log | awk '/Created_tmp_disk_tables/ &#123;print $2&#125;'` echo $(printf "%.2f" `echo "scale=2;$&#123;created_tmp_disk_tables&#125;/$&#123;created_tmp_tables&#125;"|bc`) ;; binlog_cache_disk_use) cat /tmp/mysql_status_monitor.log | awk '/Binlog_cache_disk_use/ &#123;print $2&#125;' ;; table_locks_immediate) cat /tmp/mysql_status_monitor.log | awk '/Table_locks_immediate/ &#123;print $2&#125;' ;; table_locks_waited) cat /tmp/mysql_status_monitor.log | awk '/Table_locks_waited/ &#123;print $2&#125;' ;; innodb_row_lock_waits) cat /tmp/mysql_status_monitor.log | awk '/Innodb_row_lock_waits/ &#123;print $2&#125;' ;; *) ;;esac 4、编写zabbix监控项文件,通过/usr/local/zabbix/script/mysql_get_data.sh脚本去获取对应监控的数值cat /usr/local/zabbix/etc/zabbix_agentd.conf.d/mysql_monitor_parameter.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#集群节点数量UserParameter=nodecount[*],sh /usr/local/zabbix/script/mysql_get_data.sh nodecount#系统运行时间UserParameter=uptime[*],sh /usr/local/zabbix/script/mysql_get_data.sh uptime#查看select语句的执行数UserParameter=com_select[*],sh /usr/local/zabbix/script/mysql_get_data.sh com_select#查看insert语句的执行数UserParameter=com_insert[*],sh /usr/local/zabbix/script/mysql_get_data.sh com_insert#查看update语句的执行数UserParameter=com_update[*],sh /usr/local/zabbix/script/mysql_get_data.sh com_update#查看delete语句的执行数UserParameter=com_delete[*],sh /usr/local/zabbix/script/mysql_get_data.sh com_delete#查看试图连接到MySQL(不管是否连接成功)的连接数UserParameter=connections[*],sh /usr/local/zabbix/script/mysql_get_data.sh connections#查看线程缓存内的线程的数量UserParameter=thread_cached[*],sh /usr/local/zabbix/script/mysql_get_data.sh thread_cached#当线程打开连接数UserParameter=threads_connected[*],sh /usr/local/zabbix/script/mysql_get_data.sh threads_connected#查看创建用来处理连接的线程数。如果Threads_created较大，你可能要增加thread_cache_size值UserParameter=thread_created[*],sh /usr/local/zabbix/script/mysql_get_data.sh thread_created#查看激活的(非睡眠状态)线程数UserParameter=threads_running[*],sh /usr/local/zabbix/script/mysql_get_data.sh threads_running#查看创建时间超过slow_launch_time秒的线程数。UserParameter=slow_launch_threads[*],sh /usr/local/zabbix/script/mysql_get_data.sh slow_launch_threads#查看查询时间超过long_query_time秒的查询的个数。UserParameter=slow_queries[*],sh /usr/local/zabbix/script/mysql_get_data.sh slow_queries#在服务器上执行语句的数量，只包括客户端发送给服务器的语句，并不包括存储项目执行的语句UserParameter=qps[*],sh /usr/local/zabbix/script/mysql_get_data.sh qps#事物提交数量com_commit#事物回滚数量com_rollbackUserParameter=tps[*],sh /usr/local/zabbix/script/mysql_get_data.sh tps#在buffer pool满足不了逻辑读的请求，而必须直接从硬盘读取的数量innodb_buffer_pool_reads#逻辑读的请求数innodb_buffer_pool_read_requests#buffer_read命中率UserParameter=innodb_buffer_read_hits[*],sh /usr/local/zabbix/script/mysql_get_data.sh innodb_buffer_read_hits#打开表的数量open_tables#已经打开表的数量opened_tables#table_cache命中率UserParameter=table_cache_hit[*],sh /usr/local/zabbix/script/mysql_get_data.sh table_cache_hit#thread_cache命中率UserParameter=thread_cache_hits[*],sh /usr/local/zabbix/script/mysql_get_data.sh thread_cache_hits#执行语句过程中创建的临时表created_tmp_tables#当创建的内部临时表过大，mysql会自动将表从内存中转换为磁盘上的表created_tmp_disk_tables#在磁盘上创建临时表的比例UserParameter=create_tmp_tables_hits[*],sh /usr/local/zabbix/script/mysql_get_data.sh create_tmp_tables_hits#事物使用binlog但是临时二进制日志超过binlog_cache_size，使用临时文件存储事物的语句，如果该值不为0，需要调整binlog_cache_sizeUserParameter=binlog_cache_disk_use[*],sh /usr/local/zabbix/script/mysql_get_data.sh binlog_cache_disk_use#可以立即授予表锁请求的次数UserParameter=table_locks_immediate[*],sh /usr/local/zabbix/script/mysql_get_data.sh table_locks_immediate#一个表锁的请求不能立即被授予，需要等待的次数,如果该值过高，说明数据库有性能问题，应该优化sql语句，表分区或者读写分离UserParameter=table_locks_waited[*],sh /usr/local/zabbix/script/mysql_get_data.sh table_locks_waited#操作innodb表等待行数的次数UserParameter=innodb_row_lock_waits[*],sh /usr/local/zabbix/script/mysql_get_data.sh innodb_row_lock_waits 5、修改/usr/local/zabbix/etc/zabbix_agentd.conf配置文件,添加该行参数：1Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/ 添加完成之后，需要重启zabbix_agent客户端 6、通过zabbix-web控制台，自定义一个模板，新建监控项、触发器、图形等内容，下面链接是我创建的比较简单的mysql模板，上传到百度云，仅供参考，点击下载]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] 去掉查询结果中带的mysql: [Warning] Using a password on the command line interface can be insecure]]></title>
    <url>%2F2018%2F08%2F14%2F%E5%8E%BB%E6%8E%89%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E4%B8%AD%E5%B8%A6%E7%9A%84mysql%20%5BWarning%5D%20Using%20a%20password%20on%20the%20command%20line%20interface%20can%20be%20insecure%2F</url>
    <content type="text"><![CDATA[1、一般情况为了方便，在使用mysql命令查询的时候会在-p后面直接加上密码,输出结果如下：1mysql -u root -p12345678 -BNe "select count(*) from performance_schema.replication_group_members where MEMBER_STATE='ONLINE'" 结果如下：12mysql: [Warning] Using a password on the command line interface can be insecure.3 2、为了消除结果中的[Warning]信息，只显示查询结果，可使用环境变量存储密码的方法：1export MYSQL_PWD=12345678;mysql -u root -BNe "select count(*) from performance_schema.replication_group_members where MEMBER_STATE='ONLINE'" 结果如下：13]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysql-innodb buffer pool size调整]]></title>
    <url>%2F2018%2F08%2F14%2Fmysql-innodb%20buffer%20pool%20size%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[1、查看当前数据库innodb_buffer_pool参数1show global variables like 'innodb_buffer_pool_size'; ##2、查看page_size大小1show variables like 'innodb_page_size'; 官方文档参数详解123Innodb_page_sizeInnoDB page size (default 16KB). Many values are counted in pages; the page size enables them to beeasily converted to bytes 3、查看当前内存innodb页的总数量和包含数据的页的数量12show global status like 'Innodb_buffer_pool_pages_data';show global status like 'Innodb_buffer_pool_pages_total'; 官方文档参数详解：123456Innodb_buffer_pool_pages_dataThe number of pages in the InnoDB buffer pool containing data. The number includes both dirty andclean pages.Innodb_buffer_pool_pages_totalThe total size of the InnoDB buffer pool, in pages. 4、调优参考计算方法：123val = Innodb_buffer_pool_pages_data / Innodb_buffer_pool_pages_total * 100%val &gt; 95% 则考虑增大 innodb_buffer_pool_size， 建议使用物理内存的75%val &lt; 95% 则考虑减小 innodb_buffer_pool_size， 建议设置为：Innodb_buffer_pool_pages_data * Innodb_page_size * 1.05 / (1024*1024*1024) 5、设置innodb_buffer_pool_siz大小设置命令：1set global innodb_buffer_pool_size = 17179869184; 缓冲池字节大小，单位kb，如果不设置，默认为128M5.7版本以后可以动态修改参数，但是也要修改配置文件参数，防止重启之后，参数又变成配置文件内的参数,5.7以下的版本为静态参数，需要修改配置文件，并重新启动mysql1234cat /etc/my.cnf---------innodb_buffer_pool_size = 17179869184 #设置16G--------- 6、配置参数也可使用M、G等参数，内容如下：12345/etc/my.cnf：-------------------innodb_buffer_pool_size = 16G #设置16Ginnodb_buffer_pool_size = 500M #设置500M--------------------------]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mongodb] mongodb4.0定时备份并邮件告知备份情况]]></title>
    <url>%2F2018%2F08%2F12%2Fmongodb4.0%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E5%B9%B6%E9%82%AE%E4%BB%B6%E5%91%8A%E7%9F%A5%E5%A4%87%E4%BB%BD%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[1、mongodb全量备份脚本，内容如下：cat /data/soft/mongodb_backup.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#!/bin/bash#认证用户名authuser=admin1#认证用户对应密码authpass=admin123#备份的服务器地址servername=testrepl/127.0.0.1:30000#备份的数据库实例名称instancename=test#认证数据库实例名称authdbname=admin#备份脚本运行获取到的时间戳stamp=`date +"%Y-%m-%d"`#项目名称programname=bulingbuling#备份文件目录backuppath=/data/backup#备份文件绝对路径名称backname=$&#123;backuppath&#125;/$&#123;instancename&#125;#需要删除的备份文件绝对路径名称oldstamp=`date +"%Y-%m-%d" -d "-5 day"`oldbackname=$&#123;backname&#125;-$&#123;oldstamp&#125;.dump#数据库安装路径dbpath=/data/mongodb/bin#备份操作log目录backuplogname=/tmp/mongodb_bakcup_$&#123;stamp&#125;.log#当前服务器主机名localname=`hostname`#当前服务器ip地址localip=`ip a |grep global| head -1| awk '&#123;print $2&#125;'|awk -F'/' '&#123;print $1&#125;'`#localip='65.52.165.104'#目标邮箱dest_mail='test@qq.com'#判断指定log文件是否存在，如果存在将其删除if [ -e $&#123;backuplogname&#125; ];then sudo rm -rf $&#123;backuplogname&#125;else :fi#备份执行失败发送错误邮件send_fail_mail()&#123; echo "$&#123;programname&#125;备份失败,登录服务器$&#123;localname&#125;-$&#123;localip&#125;的日志$&#123;backuplogname&#125;下查看报错！！！" |mail -s $&#123;programname&#125;数据库备份情况 $&#123;dest_mail&#125;&#125;#备份执行成功发送成功邮件 send_success_mail()&#123; echo "$&#123;programname&#125;备份成功,可登录服务器$&#123;localname&#125;-$&#123;localip&#125;的日志$&#123;backuplogname&#125;下查看备份信息。" |mail -s $&#123;programname&#125;数据库备份情况 $&#123;dest_mail&#125;&#125;#创建备份时间函数date_func()&#123; dateresult=$(($&#123;afterstamp&#125;-$&#123;beforstamp&#125;)) hour=$(($&#123;dateresult&#125;/3600)) min=$((($&#123;dateresult&#125;-$&#123;hour&#125;*3600)/60)) sec=$(($&#123;dateresult&#125;-$&#123;hour&#125;*3600-$&#123;min&#125;*60)) echo "6、本次备份运行时间为:"$&#123;hour&#125;时$&#123;min&#125;分$&#123;sec&#125;秒 &gt;&gt; $&#123;backuplogname&#125;&#125;#创建一个删除五天前的备份数据的函数del_old_bakdata()&#123; if [ -e $&#123;oldbackname&#125; ];then sudo echo "7、五天前的备份数据$&#123;oldbackname&#125;存在，进行删除" &gt;&gt; $&#123;backuplogname&#125; rm -rf $&#123;oldbackname&#125; if [ $? == 0 ];then sudo echo "7.1、备份数据删除成功" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "7.1、备份数据删除失败，注意查看失败原因" &gt;&gt; $&#123;backuplogname&#125; fi else sudo echo "7、五天前的备份数据$&#123;oldbackname&#125;不存在，不需要再删除。" &gt;&gt; $&#123;backuplogname&#125; fi &#125;#因为mongodbdump只能指定路径，不能自定义备份文件名称，因此需要对备份完成的目录重命名rename_backname_func()&#123; if [ -e $&#123;backname&#125;-$&#123;stamp&#125; ];then mv $&#123;backname&#125;-$&#123;stamp&#125; $&#123;backname&#125;-$&#123;stamp&#125;-old mv $&#123;backname&#125; $&#123;backname&#125;-$&#123;stamp&#125; if [ $? == 0 ];then echo "5、备份目录重命名成功" &gt;&gt; $&#123;backuplogname&#125; else echo "5、备份目录重命名失败,查看命名失败原因！" &gt;&gt; $&#123;backuplogname&#125; fi else mv $&#123;backname&#125; $&#123;backname&#125;-$&#123;stamp&#125; if [ $? == 0 ];then echo "5、备份目录重命名成功" &gt;&gt; $&#123;backuplogname&#125; else echo "5、备份目录重命名失败,查看命名失败原因！" &gt;&gt; $&#123;backuplogname&#125; fi fi&#125;#备份之前判断备份目录是否存在if [ -d $&#123;backuppath&#125; ];then sudo echo "1、备份目录存在,可执行备份操作" &gt;&gt; $&#123;backuplogname&#125;else sudo echo "1、备份目录不存在,手动创建" &gt;&gt; $&#123;backuplogname&#125; sudo mkdir -p $&#123;backuppath&#125; if [ $? == 0 ];then sudo echo "1.1、备份目录创建成功，可进行下面操作" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "1.1、备份目录不存在，且创建失败，无法进行下面操作，退出备份" &gt;&gt; $&#123;backuplogname&#125; exit fifi#备份之前判断备份文件是否已经存在if [ -d $&#123;backname&#125; ];then sudo echo "2、指定的备份实例目录$&#123;backname&#125;已存在，对其进行重命名" &gt;&gt; $&#123;backuplogname&#125; mv $&#123;backname&#125; $&#123;backuppath&#125;/bak-$&#123;fullbackupname&#125;-$&#123;stamp&#125;.dump if [ $? == 0 ];then sudo echo "2.1、文件已重新命名为$&#123;backuppath&#125;/bak-$&#123;fullbackupname&#125;-$&#123;stamp&#125;.dump,可继续备份" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "2.1、文件重命名失败，退出备份操作" &gt;&gt; $&#123;backuplogname&#125; exit fielse sudo echo "2、指定的备份文件不存在，开始进行备份" &gt;&gt; $&#123;backuplogname&#125;fi#备份之前时间戳beforstamp=`date +%s`#开始全量备份数据库sudo echo "3、开始全量备份数据库" &gt;&gt; $&#123;backuplogname&#125;$&#123;dbpath&#125;/mongodump -h $&#123;servername&#125; -u $&#123;authuser&#125; -p $&#123;authpass&#125; -d $&#123;instancename&#125; -o $&#123;backuppath&#125; --authenticationDatabase $&#123;authdbname&#125;backupresult=$?afterstamp=`date +%s`if [ $&#123;backupresult&#125; == 0 ];then sudo echo "4、$&#123;programname&#125;-$&#123;instancename&#125;数据库备份成功,文件名称为$&#123;backname&#125;，重命名备份文件" &gt;&gt; $&#123;backuplogname&#125; rename_backname_func date_func del_old_bakdata send_success_mailelse sudo echo "4、$&#123;programname&#125;-$&#123;instancename&#125;数据库备份失败,注意查看备份失败原因并重新备份" &gt;&gt; $&#123;backuplogname&#125; send_fail_mail exitfi 使用该脚本需要修改自己数据库对应的用户名authuser,密码authpass,邮箱dest_mail,项目名称programname,服务器名称servername,数据库实例名称instancename,mongodb数据库安装路径dbpath。其他参数可使用脚本内默认的，也可自行修改 2、配置邮件发送功能2.1、安装mailx软件1yum install -y mailx 2.2、修改配置文件/etc/mail.rc,在行尾添加一下信息：12set from=test@qq.com smtp=smtp.qq.comset smtp-auth-user=test@qq.com smtp-auth-password=testpassword smtp-auth=login 参数详解：1234from:指定发送邮件的发件人smtp:指定smtp服务器信息smtp-auth-user:允许第三方登录的用户名smtp-auth-password：允许第三方登录的密码 2.3、发送测试邮件：1echo 'test email' |mail -s 'title' test@qq.com title:指定发送文件的标题，可自行定义 3、修改备份脚本权限1chmod +x /data/soft/mongodb_backup.sh 4、将脚本添加到定时任务如：每天凌晨一点备份1shell &gt; crontab -e 10 1 * * * sh /data/soft/mongodb_backup.sh]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mongodb] mongodb4.0备份与恢复]]></title>
    <url>%2F2018%2F08%2F12%2Fmongdob4.0%20%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[1、mongodb备份命令1.1、备份之前查看备份实例的相关数据：12345678MongoDB Enterprise testrepl:PRIMARY&gt; use adminswitched to db adminMongoDB Enterprise testrepl:PRIMARY&gt; db.auth(&apos;admin1&apos;,&apos;admin123&apos;);1MongoDB Enterprise testrepl:PRIMARY&gt; use test;switched to db testMongoDB Enterprise testrepl:PRIMARY&gt; db.test_collection.find().count();844703 1.2、对于replica set集群模式命令如下：1/data/mongodb/bin/mongodump -h "testrepl/127.0.0.1:30000" -u admin1 -p admin123 -d test -o /data/backup/ --authenticationDatabase admin 结果如下：122018-08-12T03:40:01.489+0000 writing test.test_collection to 2018-08-12T03:40:03.823+0000 done dumping test.test_collection (844703 documents) 会在指定的备份目录下，生成备份实例名对应的文件夹，文件夹下有以下文件：1test_collection.bson test_collection.metadata.json 命令参数详解：1234567-h:指定当前备份主机ip--port:指定当前mongodb的启动端口-u:指定验证的用户名-d:需要备份的数据库实例-p:指定用户名对应的密码-o:指定备份的路径--authenticationDatabase:认证数据库 备份过程没有加上指定认证数据库“–authenticationDatabase admin”,会报一下错误1Failed: error connecting to db server: server returned error on SASL authentication step: Authentication failed. 1.3、对于单节点备份命令如下：1/data/mongodb/bin/mongodump -h 127.0.0.1 --port 30000 -u admin1 -p admin123 -d test -o /data/backup --authenticationDatabase admin 2、拷贝备份出来的文件，新建一台新节点(10.0.7.36)mongodb,并做恢复测试,恢复命令如下(因为测试环境节点有限，该恢复操作是将一个集群模式的备份，恢复到一个单点上的操作)：1/data/mongodb/bin/mongorestore -h 10.0.7.36 --port 30000 -u admin1 -p admin123 -d test /data/backup/test --authenticationDatabase admin 恢复输出结果如下：1234567892018-08-11T14:19:48.860+0000 the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead2018-08-11T14:19:48.860+0000 building a list of collections to restore from /data/backup/test dir2018-08-11T14:19:48.885+0000 reading metadata for test.test_collection from /data/backup/test/test_collection.metadata.json2018-08-11T14:19:48.972+0000 restoring test.test_collection from /data/backup/test/test_collection.bson2018-08-11T14:19:51.781+0000 [###########.............] test.test_collection 28.4MB/57.1MB (49.8%)2018-08-11T14:19:54.490+0000 [########################] test.test_collection 57.1MB/57.1MB (100.0%)2018-08-11T14:19:54.490+0000 restoring indexes for collection test.test_collection from metadata2018-08-11T14:19:57.737+0000 finished restoring test.test_collection (844703 documents)2018-08-11T14:19:57.737+0000 done 控制台登录，查看数据是否一致：123456789101112131415MongoDB Enterprise &gt; use adminswitched to db adminMongoDB Enterprise &gt; db.auth(&apos;admin1&apos;,&apos;admin123&apos;);1MongoDB Enterprise &gt; show dbs;admin 0.000GBconfig 0.000GBlocal 0.000GBtest 0.031GBMongoDB Enterprise &gt; use testswitched to db testMongoDB Enterprise &gt; show tables;test_collectionMongoDB Enterprise &gt; db.test_collection.find().count();844703 恢复完成]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] 使用innodb trx和innodb lock信息表查看锁事物]]></title>
    <url>%2F2018%2F08%2F11%2F%E4%BD%BF%E7%94%A8innodb%20trx%E5%92%8Cinnodb%20lock%E4%BF%A1%E6%81%AF%E8%A1%A8%E6%9F%A5%E7%9C%8B%E9%94%81%E4%BA%8B%E7%89%A9%2F</url>
    <content type="text"><![CDATA[1、插入表测试数据12345678select * from aaa;+----+------+-------------+| id | name | telephone |+----+------+-------------+| 1 | a | 11111111111 || 2 | b | 22222222222 || 3 | c | 33333333333 |+----+------+-------------+ 2、创建三个会话，造成锁事物sessin 1:123BEGIN;SELECT id FROM aaa FOR UPDATE;SELECT SLEEP(60); session 2:1SELECT name FROM aaa FOR UPDATE; sesion 3:1SELECT telephone FROM aaa FOR UPDATE; 3、使用以下查询来查看正在等待的事务以及阻止它们的事务：session 41234567891011121314151617181920SELECT r.trx_id waiting_trx_id, r.trx_mysql_thread_id waiting_thread, r.trx_query waiting_query, b.trx_id blocking_trx_id, b.trx_mysql_thread_id blocking_thread, b.trx_query blocking_queryFROM information_schema.innodb_lock_waits wINNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_idINNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;查询结果如下：+----------------+----------------+--------------------------------------+-----------------+-----------------+---------------------------------+| waiting_trx_id | waiting_thread | waiting_query | blocking_trx_id | blocking_thread | blocking_query |+----------------+----------------+--------------------------------------+-----------------+-----------------+---------------------------------+| 2488 | 58 | SELECT telephone FROM aaa FOR UPDATE | 2487 | 57 | SELECT name FROM aaa FOR UPDATE || 2488 | 58 | SELECT telephone FROM aaa FOR UPDATE | 2486 | 53 | SELECT SLEEP(100) || 2487 | 57 | SELECT name FROM aaa FOR UPDATE | 2486 | 53 | SELECT SLEEP(100) |+----------------+----------------+--------------------------------------+-----------------+-----------------+---------------------------------+ 上述sql语句可能太繁琐，也可使用下面语句查询12345678SELECT waiting_trx_id, waiting_pid, waiting_query, blocking_trx_id, blocking_pid, blocking_queryFROM sys.innodb_lock_waits; 4、如果查询造成锁事物的会话已经变成空闲，上面查询出来的数据会变为空，可以通过process_id,来查询琐事物12show full processlist;| 57 | root | localhost | aaaa | Sleep | 566 | | NULL | 查询出process_id为57 5、通过processlist_id查询出thread_id123456SELECT THREAD_ID FROM performance_schema.threads WHERE PROCESSLIST_ID = 57;+-----------+| THREAD_ID |+-----------+| 79 |+-----------+ 6、根据thread_id查询出来造成锁事物的sql语句123456SELECT THREAD_ID, SQL_TEXT FROM performance_schema.events_statements_current WHERE THREAD_ID = 79\G*************************** 1. row ***************************THREAD_ID: 79 SQL_TEXT: SELECT name FROM aaa FOR UPDATE1 row in set (0.00 sec) 7、如果线程执行的最后一个查询不足以确定锁定的原因，则可以查询Performance Schema events_statements_history 表以查看该线程执行的最后10个语句。1234567SELECT THREAD_ID, SQL_TEXT FROM performance_schema.events_statements_history WHERE THREAD_ID = 79 ORDER BY EVENT_ID;+-----------+---------------------------------+| THREAD_ID | SQL_TEXT |+-----------+---------------------------------+| 79 | SELECT name FROM aaa FOR UPDATE |+-----------+---------------------------------+]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction]]></title>
    <url>%2F2018%2F08%2F11%2Fmysql-%20Lock%20wait%20timeout%20exceeded%3B%20try%20restarting%20transaction%2F</url>
    <content type="text"><![CDATA[1、对一个表进行ddl操作123mysql&gt;ALTER TABLE deposit_coin_order_user add `txid` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '区块链id' ;提示报错：ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 查看该表数据只有39行数据：123456select count(*) from deposit_coin_order_user;+----------+| count(*) |+----------+| 39 |+----------+ 2、查看事物表Innodb_trx是否记录相关事物，如果有找到该事物的‘trx_mysql_thread_id’123456789101112131415161718192021222324252627SELECT * FROM information_schema.INNODB_TRX\G*************************** 1. row *************************** trx_id: 421462261342800 trx_state: RUNNING trx_started: 2018-08-10 08:24:58 trx_requested_lock_id: NULL trx_wait_started: NULL trx_weight: 0 trx_mysql_thread_id: 12989053 trx_query: NULL trx_operation_state: NULL trx_tables_in_use: 0 trx_tables_locked: 0 trx_lock_structs: 0 trx_lock_memory_bytes: 1136 trx_rows_locked: 0 trx_rows_modified: 0 trx_concurrency_tickets: 0 trx_isolation_level: REPEATABLE READ trx_unique_checks: 1 trx_foreign_key_checks: 1trx_last_foreign_key_error: NULL trx_adaptive_hash_latched: 0 trx_adaptive_hash_timeout: 0 trx_is_read_only: 0trx_autocommit_non_locking: 01 row in set (0.00 sec) 使用show full processlist查看是否有‘trx_mysql_thread_id’对应的进程，如果有就证明这个sleep的线程事务一直没有commit或者rollback而是卡住了，我们需要手动kill掉。没有的话看看有没有正在执行的很慢SQL记录线程。12mysql &gt; show full processlist;| 12989053 | cwreadonly | 10.1.10.9:51650 | exchange_market | Sleep | 1189 | | NULL 3、发现有id为12989053的sql，需要手动kill掉mysql &gt; KILL 12989053; 4、再次执行ddl语句，正常执行ALTER TABLE deposit_coin_order_user add txid varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT ‘区块链id’ ;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysql定时备份及邮件告知备份情况]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E5%8F%8A%E9%82%AE%E4%BB%B6%E5%91%8A%E7%9F%A5%E5%A4%87%E4%BB%BD%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[1、mysql全量备份脚本，内容如下：cat /data/soft/mysql_backup.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#!/bin/bash#数据库用户名dbuser=test#数据库密码dbpass=test#备份脚本运行获取到的时间戳stamp=`date +"%Y-%m-%d"`#项目名称programname=mw#备份文件名称前缀fullbackupname=$&#123;programname&#125;-dbfullbak#备份文件目录backuppath=/data/backup#备份文件绝对路径名称backname=$backuppath/$&#123;fullbackupname&#125;-$&#123;stamp&#125;.dump#需要删除的备份文件绝对路径名称oldstamp=`date +"%Y-%m-%d" -d "-5 day"`oldbackname=$backuppath/$&#123;fullbackupname&#125;-$&#123;oldstamp&#125;.dump#数据库安装路径dbpath=/data/mysql/bin#备份操作log目录backuplogname=/tmp/backup_$&#123;stamp&#125;.log#当前服务器主机名localname=`hostname`#当前服务器ip地址localip=`ip a |grep global| head -1| awk '&#123;print $2&#125;'|awk -F'/' '&#123;print $1&#125;'`#localip='65.52.165.104'#目标邮箱dest_mail='test@qq.com'#判断指定log文件是否存在，如果存在将其删除if [ -e $&#123;backuplogname&#125; ];then sudo rm -rf $&#123;backuplogname&#125;else :fi#备份执行失败发送错误邮件send_fail_mail()&#123; echo "$&#123;programname&#125;备份失败,登录服务器$&#123;localname&#125;-$&#123;localip&#125;的日志$&#123;backuplogname&#125;下查看报错！！！" |mail -s $&#123;programname&#125;数据库备份情况 $&#123;dest_mail&#125;&#125;#备份执行成功发送成功邮件 send_success_mail()&#123; echo "$&#123;programname&#125;备份成功,可登录服务器$&#123;localname&#125;-$&#123;localip&#125;的日志$&#123;backuplogname&#125;下查看备份信息。" |mail -s $&#123;programname&#125;数据库备份情况 $&#123;dest_mail&#125;&#125;#创建备份时间函数date_func()&#123; dateresult=$(($&#123;afterstamp&#125;-$&#123;beforstamp&#125;)) hour=$(($&#123;dateresult&#125;/3600)) min=$((($&#123;dateresult&#125;-$&#123;hour&#125;*3600)/60)) sec=$(($&#123;dateresult&#125;-$&#123;hour&#125;*3600-$&#123;min&#125;*60)) echo "5、本次备份运行时间为:"$&#123;hour&#125;时$&#123;min&#125;分$&#123;sec&#125;秒 &gt;&gt; $&#123;backuplogname&#125;&#125;#创建一个删除五天前的备份数据的函数del_old_bakdata()&#123; if [ -e $&#123;oldbackname&#125; ];then sudo echo "6、五天前的备份数据$&#123;oldbackname&#125;存在，进行删除" &gt;&gt; $&#123;backuplogname&#125; rm -rf $&#123;oldbackname&#125; if [ $? == 0 ];then sudo echo "6.1、备份数据删除成功" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "6.1、备份数据删除失败，注意查看失败原因" &gt;&gt; $&#123;backuplogname&#125; fi else sudo echo "6、五天前的备份数据$&#123;oldbackname&#125;不存在，不需要再删除。" &gt;&gt; $&#123;backuplogname&#125; fi &#125;#备份之前判断备份目录是否存在if [ -d $&#123;backuppath&#125; ];then sudo echo "1、备份目录存在,可执行备份操作" &gt;&gt; $&#123;backuplogname&#125;else sudo echo "1、备份目录不存在,手动创建" &gt;&gt; $&#123;backuplogname&#125; sudo mkdir -p $&#123;backuppath&#125; if [ $? == 0 ];then sudo echo "1.1、备份目录创建成功，可进行下面操作" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "1.1、备份目录不存在，且创建失败，无法进行下面操作，退出备份" &gt;&gt; $&#123;backuplogname&#125; exit fifi#备份之前判断备份文件是否已经存在if [ -e $&#123;backname&#125; ];then sudo echo "2、指定的备份文件$&#123;backname&#125;已存在，对其进行重命名" &gt;&gt; $&#123;backuplogname&#125; mv $&#123;backname&#125; $&#123;backuppath&#125;/bak-$&#123;fullbackupname&#125;-$&#123;stamp&#125;.dump if [ $? == 0 ];then sudo echo "2.1、文件已重新命名为$&#123;backuppath&#125;/bak-$&#123;fullbackupname&#125;-$&#123;stamp&#125;.dump,可继续备份" &gt;&gt; $&#123;backuplogname&#125; else sudo echo "2.1、文件重命名失败，退出备份操作" &gt;&gt; $&#123;backuplogname&#125; exit fielse sudo echo "2、指定的备份文件不存在，开始进行备份" &gt;&gt; $&#123;backuplogname&#125;fi#备份之前时间戳beforstamp=`date +%s`#开始全量备份数据库sudo echo "3、开始全量备份数据库" &gt;&gt; $&#123;backuplogname&#125;$&#123;dbpath&#125;/mysqldump -u$&#123;dbuser&#125; -p$&#123;dbpass&#125; --all-databases --set-gtid-purged=OFF &gt; $&#123;backname&#125;backupresult=$?afterstamp=`date +%s`if [ $&#123;backupresult&#125; == 0 ];then sudo echo "4、$&#123;programname&#125;数据库备份成功,文件名称为$&#123;backname&#125;，准备删除五天前的备份数据" &gt;&gt; $&#123;backuplogname&#125; date_func del_old_bakdata send_success_mailelse sudo echo "4、$&#123;programname&#125;数据库备份失败,注意查看备份失败原因并重新备份" &gt;&gt; $&#123;backuplogname&#125; send_fail_mail exitfi 使用该脚本需要修改自己数据库对应的用户名dbuser,密码dbpass,邮箱dest_mail,项目名称programname,mysql数据库安装路径dbpath。其他参数可使用脚本内默认的，也可自行修改 2、配置邮件发送功能2.1、安装mailx软件1yum install -y mailx 2.2、修改配置文件/etc/mail.rc,在行尾添加一下信息：12set from=test@qq.com smtp=smtp.qq.comset smtp-auth-user=test@qq.com smtp-auth-password=testpassword smtp-auth=login 参数详解：1234from:指定发送邮件的发件人smtp:指定smtp服务器信息smtp-auth-user:允许第三方登录的用户名smtp-auth-password：允许第三方登录的密码 2.3、发送测试邮件：1echo 'test email' |mail -s 'title' test@qq.com title:指定发送文件的标题，可自行定义 3、修改备份脚本权限1chmod +x /data/soft/mysql_backup.sh 4、将脚本添加到定时任务如：每天凌晨一点备份1shell &gt; crontab -e 10 1 * * * sh /data/soft/mysql_backup.sh]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysqldump逻辑备份及恢复]]></title>
    <url>%2F2018%2F08%2F09%2Fmysqldump%E9%80%BB%E8%BE%91%E5%A4%87%E4%BB%BD%E5%8F%8A%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[0、mysql实验版本15.7.22-log 1、mysqldump备份操作详解：123456789101112131415161718-d --no-data No row information 只导出数据结构-t --no-create-info 只导出数据（不包含结构）1）导出所有数据库mysqldump -u root -p --all-databases &gt; all_db.dump2）导出指定数据库mysqldump -u root -p zabbixDB &gt; zabbix.dump3) 导出多个数据库mysqldump -u root -p --databases zabbixDB mysql &gt; zabbix_mysql.dump4）导出一个表mysqldump -u root -p zabbixDB task &gt; zabbixDB_task.dump5)导出一个数据库的多个表mysqldump -u root -p --databases zabbixDB --tables trends users &gt; zabbix_trends_users.dump6)条件导出----导出db1表a1中id=1的数据mysqldump -uroot -p --databases db1 --tables a1 --where=&apos;id=1&apos; &gt; db1_a1_id.dump7)将h1服务器中的db1数据库的所有数据导入到h2中的db2数据库中，db2的数据库必须存在否则会报错mysqldump --host=h1 -uroot -proot --databases db1 |mysql --host=h2 -uroot -proot db28)压缩备份mysqldump -uroot -p --databases zabbixDB 2&gt;/dev/null |gzip &gt; zabbixDB.gz ##开始实验 2、源库插入测试数据1234create database aaaa;use aaaa;create table aa (id int primary key);insert into aa values(&apos;1&apos;); 3、导出备份1mysqldump -u root -p --all-databases --set-gtid-purged=OFF &gt; /tmp/test.dump 4、在目标数据库进行还原，全库导入1mysql -u root -p12345678 &lt; test.dump 因为mysqldump属于逻辑备份，恢复步骤为先检查要恢复的database是否存在，如果不存在就手动创建，如果存在就进入database去检查表是否存在，如果存在，会先删除再手动创建,表创建完成之后插入数据,分析dump文件，具体内容如下： 4.1、创建database：12345---- Current Database: `aaaa`--CREATE DATABASE /*!32312 IF NOT EXISTS*/ `aaaa` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;USE `aaaa`; 4.2、检查并创建表aaa:1234567891011---- Table structure for table `aaa`--DROP TABLE IF EXISTS `aaa`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `aaa` ( `id` int(11) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;/*!40101 SET character_set_client = @saved_cs_client */; 4.3、对表aaa插入备份出来的数据：12345678---- Dumping data for table `aaa`--LOCK TABLES `aaa` WRITE;/*!40000 ALTER TABLE `aaa` DISABLE KEYS */;INSERT INTO `aaa` VALUES (1);/*!40000 ALTER TABLE `aaa` ENABLE KEYS */;UNLOCK TABLES;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mongodb] mongodb sharding集群配置]]></title>
    <url>%2F2018%2F08%2F08%2Fmongodb-sharding-cluster%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[0、前提需求为了满足mongodb数据库高可用环境，可以使用配置副本集CSRS（config server replica set)，搭建方法点击此处,但是当业务吞吐量特别高的时刻，单台节点已经不能满足访问需求，因此需要考虑sharding cluster 模式，提高访问性能。 1、将集群架构从csrs调整为sharding cluster,下文按照上面搭建的csrs架构继续调整：1.1、节点信息如下：主：10.0.7.53从：10.0.7.51仲裁：10.0.7.50依次关闭仲裁、从、主节点，修改配置文件mongodb.conf，添加如下信息：12sharding: clusterRole: shardsvr 1.2、修改完三个节点之后，依次启动主，从，仲裁三个节点，进入控制台使用rs.status()，查看集群状态是否正常。为了保证停机时间较短，可使用rs.stepDown()分别进行主从切换，对从库进行配置并重启。 2、新建一个shard1集群节点，操作如下(三个节点都要执行）：2.1、节点信息如下：从：10.0.7.53主：10.0.7.51仲裁：10.0.7.502.2、拷贝一份mongodb.conf文件，并重新命名cp mongodb.conf shard1mongodb.conf2.3、主节点需要在无需验证的模式下，先配置用户名密码。之后修改（三个节点）shard1mongodb.conf配置文件内容如下：cat shard1mongodb.conf123456789101112131415161718192021222324252627282930313233343536373839404142# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/# where to write logging data.systemLog: destination: file logAppend: true path: /data/mongodb/shard1/log/mongod.log# Where and how to store data.storage: dbPath: /data/mongodb/shard1/data/ journal: enabled: true# engine:# mmapv1:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /data/mongodb/shard1/log/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo# network interfacesnet: port: 30001 bindIp: 127.0.0.1,10.0.7.53 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.#security:security: authorization: enabled keyFile: /data/mongodb/shard1/mongodb.keyfile#operationProfiling:#replication:replication: replSetName: "shard1"#sharding:sharding: clusterRole: shardsvr## Enterprise-Only Options#auditLog:#snmp: 注意修改sharding、port、path、replname等参数 2.4、创建相应的数据目录和日志目录：1mkdir -p /data/mongodb/shard1/&#123;log,data&#125; 2.5、生成keyfile文件并拷贝keyfile文件到指定目录：1cp mongodb.keyfile /data/mongodb/shard1/ 2.6、三个节点启动mongodb-shard1:1/data/mongodb/bin/mongod -f /data/mongodb/shard1mongodb.conf 2.7、初始化集群配置： /data/mongodb/bin/mongo –port 30001rs.initiate( { _id : “shard”, members: [ { _id : 0, host : “10.0.7.53:30001” }, { _id : 1, host : “10.0.7.50:30001” }, { _id : 2, host : “10.0.7.51:30001”,”arbiterOnly” : true } ] })2.8、查看集群节点信息：1rs.status(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117&#123; "set" : "shard", "date" : ISODate("2018-08-09T03:13:34.697Z"), "myState" : 2, "term" : NumberLong(1), "syncingTo" : "10.0.7.50:30001", "syncSourceHost" : "10.0.7.50:30001", "syncSourceId" : 1, "heartbeatIntervalMillis" : NumberLong(2000), "optimes" : &#123; "lastCommittedOpTime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "readConcernMajorityOpTime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "appliedOpTime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "durableOpTime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125; &#125;, "lastStableCheckpointTimestamp" : Timestamp(1533784355, 1), "members" : [ &#123; "_id" : 0, "name" : "10.0.7.53:30001", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 47039, "optime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-09T03:13:25Z"), "syncingTo" : "10.0.7.50:30001", "syncSourceHost" : "10.0.7.50:30001", "syncSourceId" : 1, "infoMessage" : "", "configVersion" : 1, "self" : true, "lastHeartbeatMessage" : "" &#125;, &#123; "_id" : 1, "name" : "10.0.7.50:30001", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 46862, "optime" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "optimeDurable" : &#123; "ts" : Timestamp(1533784405, 1), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-09T03:13:25Z"), "optimeDurableDate" : ISODate("2018-08-09T03:13:25Z"), "lastHeartbeat" : ISODate("2018-08-09T03:13:33.395Z"), "lastHeartbeatRecv" : ISODate("2018-08-09T03:13:32.735Z"), "pingMs" : NumberLong(1), "lastHeartbeatMessage" : "", "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "infoMessage" : "", "electionTime" : Timestamp(1533737562, 1), "electionDate" : ISODate("2018-08-08T14:12:42Z"), "configVersion" : 1 &#125;, &#123; "_id" : 2, "name" : "10.0.7.51:30001", "health" : 1, "state" : 7, "stateStr" : "ARBITER", "uptime" : 46862, "lastHeartbeat" : ISODate("2018-08-09T03:13:34.660Z"), "lastHeartbeatRecv" : ISODate("2018-08-09T03:13:34.658Z"), "pingMs" : NumberLong(0), "lastHeartbeatMessage" : "", "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "infoMessage" : "", "configVersion" : 1 &#125; ], "ok" : 1, "operationTime" : Timestamp(1533784405, 1), "$gleStats" : &#123; "lastOpTime" : Timestamp(0, 0), "electionId" : ObjectId("000000000000000000000000") &#125;, "lastCommittedOpTime" : Timestamp(1533784405, 1), "$configServerState" : &#123; "opTime" : &#123; "ts" : Timestamp(1533784394, 1), "t" : NumberLong(1) &#125; &#125;, "$clusterTime" : &#123; "clusterTime" : Timestamp(1533784408, 1), "signature" : &#123; "hash" : BinData(0,"dToZVSHbihPkQILJVl0qcSY+8ys="), "keyId" : NumberLong("6587344633552961565") &#125; &#125;&#125; 3、新建一个config-server集群节点，操作如下(三个节点都要执行）：3.1、节点信息如下：123从：10.0.7.53从：10.0.7.51主：10.0.7.50 3.2、拷贝一份mongodb.conf文件，并重新命名1cp shard1mongodb.conf configmongodb.conf 3.3、主节点需要在无需验证的模式下，先配置用户名密码。之后修改（三个节点）configmongodb.conf配置文件内容如下：cat configmongodb.conf123456789101112131415161718192021222324252627282930313233343536373839404142# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/# where to write logging data.systemLog: destination: file logAppend: true path: /data/mongodb/config/log/mongod.log# Where and how to store data.storage: dbPath: /data/mongodb/config/data/ journal: enabled: true# engine:# mmapv1:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /data/mongodb/config/log/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo# network interfacesnet: port: 30002 bindIp: 127.0.0.1,10.0.7.53 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.#security:#security:# authorization: enabled# keyFile: /data/mongodb/config/mongodb.keyfile#operationProfiling:#replication:replication: replSetName: "config"#sharding:sharding: clusterRole: configsvr## Enterprise-Only Options#auditLog:#snmp: 注意修改sharding、repl、port、path3.4、创建相应的数据目录和日志目录：1mkdir -p /data/mongodb/config/&#123;log,data&#125; 3.5、三个节点启动mongodb-shard1:1/data/mongodb/bin/mongod --configsvr -f /data/mongodb/configmongodb.conf 启动config-server服务需要指定参数，否则初始化集群的时候会报错：1"errmsg" : "Nodes being used for config servers must be started with the --configsvr flag" 3.6、初始化集群配置： /data/mongodb/bin/mongo –port 30002rs.initiate( { _id : “config”, configsvr: true, members: [ { _id : 0, host : “10.0.7.53:30002” }, { _id : 1, host : “10.0.7.50:30002” }, { _id : 2, host : “10.0.7.51:30002” } ] })3.7、查看集群信息：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117rs.status();&#123; "set" : "config", "date" : ISODate("2018-08-06T08:29:14.472Z"), "myState" : 1, "term" : NumberLong(1), "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "heartbeatIntervalMillis" : NumberLong(2000), "optimes" : &#123; "lastCommittedOpTime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "readConcernMajorityOpTime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "appliedOpTime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "durableOpTime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125; &#125;, "lastStableCheckpointTimestamp" : Timestamp(1533544151, 1), "members" : [ &#123; "_id" : 0, "name" : "10.0.7.53:30002", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 15, "optime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "optimeDurable" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-06T08:29:11Z"), "optimeDurableDate" : ISODate("2018-08-06T08:29:11Z"), "lastHeartbeat" : ISODate("2018-08-06T08:29:14.161Z"), "lastHeartbeatRecv" : ISODate("2018-08-06T08:29:12.674Z"), "pingMs" : NumberLong(0), "lastHeartbeatMessage" : "", "syncingTo" : "10.0.7.51:30002", "syncSourceHost" : "10.0.7.51:30002", "syncSourceId" : 2, "infoMessage" : "", "configVersion" : 1 &#125;, &#123; "_id" : 1, "name" : "10.0.7.50:30002", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 15, "optime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "optimeDurable" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-06T08:29:11Z"), "optimeDurableDate" : ISODate("2018-08-06T08:29:11Z"), "lastHeartbeat" : ISODate("2018-08-06T08:29:14.164Z"), "lastHeartbeatRecv" : ISODate("2018-08-06T08:29:12.680Z"), "pingMs" : NumberLong(1), "lastHeartbeatMessage" : "", "syncingTo" : "10.0.7.51:30002", "syncSourceHost" : "10.0.7.51:30002", "syncSourceId" : 2, "infoMessage" : "", "configVersion" : 1 &#125;, &#123; "_id" : 2, "name" : "10.0.7.51:30002", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 59, "optime" : &#123; "ts" : Timestamp(1533544151, 2), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-06T08:29:11Z"), "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "infoMessage" : "could not find member to sync from", "electionTime" : Timestamp(1533544150, 1), "electionDate" : ISODate("2018-08-06T08:29:10Z"), "configVersion" : 1, "self" : true, "lastHeartbeatMessage" : "" &#125; ], "ok" : 1, "operationTime" : Timestamp(1533544151, 2), "$clusterTime" : &#123; "clusterTime" : Timestamp(1533544151, 2), "signature" : &#123; "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="), "keyId" : NumberLong(0) &#125; &#125;&#125; 4、配置mongs(mongodb-router),用于客户端连接到mongodb集群，为防止单点故障，可配置多个mongos节点4.1、拷贝一份配置文件，并重命名1cp configmongodb.conf routermongodb.conf 4.2、修改配置文件参数，内容如下：cat routermongodb.conf12345678910111213141516171819202122232425262728293031323334353637383940414243444546# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/routeruration-options/# where to write logging data.systemLog: destination: file logAppend: true path: /data/mongodb/router/log/mongod.log# Where and how to store data.#storage:# dbPath: /data/mongodb/router/data/# journal:# enabled: true# engine:# mmapv1:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /data/mongodb/router/log/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo# network interfacesnet: port: 30004 bindIp: 127.0.0.1,10.0.7.53 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.#security:#security:# authorization: enabled#operationProfiling:#replication:#sharding:sharding: configDB: config/10.0.7.53:30002,10.0.7.51:30002,10.0.7.50:30002## Enterprise-Only Options#auditLog:#snmp: 注意修改sharding,port参数，注释掉storage参数4.3、创建router日志目录1mkdir -p /data/mongodb/router/log 4.4、启动mongos1/data/mongodb/bin/mongos -f /data/mongodb/routermongodb.conf 4.5、为模拟生产环境数据，对testrepl集群节点，插入部分数据,批量插入脚本如下：12345678910use testvar bulk = db.test_collection.initializeUnorderedBulkOp();people = [&quot;Marc&quot;, &quot;Bill&quot;, &quot;George&quot;, &quot;Eliot&quot;, &quot;Matt&quot;, &quot;Trey&quot;, &quot;Tracy&quot;, &quot;Greg&quot;, &quot;Steve&quot;, &quot;Kristina&quot;, &quot;Katie&quot;, &quot;Jeff&quot;];for(var i=0; i&lt;1000000; i++)&#123; user_id = i; name = people[Math.floor(Math.random()*people.length)]; number = Math.floor(Math.random()*10001); bulk.insert( &#123; &quot;user_id&quot;:user_id, &quot;name&quot;:name, &quot;number&quot;:number &#125;);&#125;bulk.execute(); 4.6、连接到mongos123shell &gt; mongo --host 10.0.7.50 --port 30004mongos&gt; use adminmongos&gt; db.auth('admin1','admin123'); 4.7、将节点添加到集群内：12mongos&gt; sh.addShard(&quot;testrepl/10.0.7.53:30000&quot;)mongos&gt; sh.addShard(&quot;shard1/10.0.7.53:30001&quot;) 4.8、使数据库test支持sharding123456mongos&gt; sh.enableSharding(&quot;test&quot;)mongos&gt; use test#在拆分键上创建索引mongos&gt; db.test_collection.createIndex( &#123; number : 1 &#125; )#拆分集合mongos&gt; sh.shardCollection(&apos;test.mycol2&apos;, &#123;&apos;_id&apos;: 1&#125;) 4.9、查看拆分结果,(可多次重复4.5步骤进行测试）sh.status()或者db.printShardingStatus()123456789101112131415161718192021222324252627282930313233343536373839404142434445--- Sharding Status --- sharding version: &#123; "_id" : 1, "minCompatibleVersion" : 5, "currentVersion" : 6, "clusterId" : ObjectId("5b6af30b5025146bfd45717b") &#125; shards: &#123; "_id" : "shard", "host" : "shard/10.0.7.50:30001,10.0.7.53:30001", "state" : 1 &#125; &#123; "_id" : "testrepl", "host" : "testrepl/10.0.7.50:30000,10.0.7.53:30000", "state" : 1 &#125; active mongoses: "4.0.0" : 1 autosplit: Currently enabled: yes balancer: Currently enabled: yes Currently running: no Failed balancer rounds in last 5 attempts: 0 Migration Results for the last 24 hours: 4 : Success databases: &#123; "_id" : "config", "primary" : "config", "partitioned" : true &#125; config.system.sessions shard key: &#123; "_id" : 1 &#125; unique: false balancing: true chunks: shard 1 &#123; "_id" : &#123; "$minKey" : 1 &#125; &#125; --&gt;&gt; &#123; "_id" : &#123; "$maxKey" : 1 &#125; &#125; on : shard Timestamp(1, 0) &#123; "_id" : "test", "primary" : "testrepl", "partitioned" : true, "version" : &#123; "uuid" : UUID("185a3842-639f-42b0-89a1-afdc8dcdfbe7"), "lastMod" : 1 &#125; &#125; test.test_collection shard key: &#123; "number" : 1 &#125; unique: false balancing: true chunks: shard 4 testrepl 4 &#123; "number" : &#123; "$minKey" : 1 &#125; &#125; --&gt;&gt; &#123; "number" : 2394 &#125; on : shard Timestamp(2, 0) &#123; "number" : 2394 &#125; --&gt;&gt; &#123; "number" : 4791 &#125; on : shard Timestamp(3, 0) &#123; "number" : 4791 &#125; --&gt;&gt; &#123; "number" : 7194 &#125; on : shard Timestamp(4, 0) &#123; "number" : 7194 &#125; --&gt;&gt; &#123; "number" : 7892 &#125; on : shard Timestamp(5, 0) &#123; "number" : 7892 &#125; --&gt;&gt; &#123; "number" : 8591 &#125; on : testrepl Timestamp(5, 1) &#123; "number" : 8591 &#125; --&gt;&gt; &#123; "number" : 9287 &#125; on : testrepl Timestamp(3, 4) &#123; "number" : 9287 &#125; --&gt;&gt; &#123; "number" : 9589 &#125; on : testrepl Timestamp(3, 5) &#123; "number" : 9589 &#125; --&gt;&gt; &#123; "number" : &#123; "$maxKey" : 1 &#125; &#125; on : testrepl Timestamp(4, 1) 5、大功告成，客户端访问mongodb集群，只需连接mongos对应的ip、port即可]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mysql] mysql-mha主从环境，从库报错Error_code: 1062]]></title>
    <url>%2F2018%2F08%2F07%2F5.7.22-log%E7%89%88%E6%9C%ACmysql%2Cmha%E4%B8%BB%E4%BB%8E%E7%8E%AF%E5%A2%83%EF%BC%8C%E4%BB%8E%E5%BA%93%E6%8A%A5%E9%94%99%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[0、数据库版本信息：15.7.22 1、从库报错信息1234Last_SQL_Error: Could not execute Write_rows event on table test.tb1;Duplicate entry '4' for key 'PRIMARY',Error_code: 1062;handler error HA_ERR_FOUND_DUPP_KEY; the event's master log mysql-binlog.000005, end_log_pos 273273632 2、解决方法2.1、在主库上查询二进制文件信息：1/data/mysql/bin/mysqlbinlog -v --stop-position=273273632 /data/mysql/log/mysql-binlog.000005 &gt; /tmp/f.log 2.2、过滤出报错的pos所对应的行数：1cat /tmp/f.log | awk '/end_log_pos 273273632/ &#123;print NR&#125;' 122556452 2.3、根据查询到的行数，查看其上下文：1cat /tmp/f.log | awk 'NR==22556442,NR==22556492' 2.4、查询到insert的插入语句1234567### INSERT INTO `test`.`tb1`### SET### @1=4### @2='ERC20'### @3='GTO'### @4=1533176390ROLLBACK /* added by mysqlbinlog */ /*!*/; 2.5、在从库上执行下面操作，停止主从同步1stop slave; 2.6、删除报错提示的对应的行：123use test;delete from tb1 where id=4;select * from tb1; 2.7、重新启动主从同步，查看节点信息正常：12start slave;show slave status\G;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mongodb] mongodb集群配置一主一从一仲裁]]></title>
    <url>%2F2018%2F08%2F05%2Fmongodb-%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[1、首先安装在三个节点安装mongodb,安装方法详见 mongodb单点安装 2、集群节点信息：123主：10.0.7.53从：10.0.7.51仲裁：10.0.7.50 3、启动主节点，进入主节点控制台，3.1、创建管理员用户名、密码：12345678910shell &gt; /data/mongodb/bin/mongo --port 30000MongoDB Enterprise testrepl:PRIMARY&gt;use adminMongoDB Enterprise testrepl:PRIMARY&gt;db.createUser( &#123; user: "admin", pwd: "abc123", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125; ] &#125;) 使用userAdminAnyDatabase的role权限去查看rs.status();会提示“not authorized on admin to execute command”,建议授予root权限：1234567db.createUser( &#123; user: "admin1", pwd: "admin123", roles: [ &#123; role: "root", db: "admin" &#125; ] &#125;) 3.2、查看创建的管理员信息：1MongoDB Enterprise testrepl:PRIMARY&gt; db.system.users.find() 3.3、退出控制台，修改配置文件mongodb.conf(每个节点都要配置)：12security: authorization: enabled 4、在主节点上，生成秘钥文件4.1、生成密钥文件，用于集群之间互相通信：1openssl rand -base64 756 &gt; /data/mongodb/mongodb.keyfile 4.2、更改文件权限以仅为文件所有者提供读取权限1chmod 400 /data/mongodb/mongodb.keyfile 4.3、将密钥文件复制到每个副本集成员12scp /data/mongodb/mongodb.keyfile root@10.0.7.51:/data/mongodb/scp /data/mongodb/mongodb.keyfile root@10.0.7.50:/data/mongodb/ 4.4、修改配置文件mongodb.conf，添加keyfile参数(每个节点都要配置)：12security: keyFile: /data/mongodb/mongodb.keyfile 5、配置集群5.1、修改配置文件mongodb.conf，添加集群配置参数(每个节点都要配置)：12replication: replSetName: "testrepl" replSetName:设置集群名称，根据自己需求自定义（三个节点要保持一直） 5.2、重新启动mongodb1/data/mongodb/bin/mongod -f /data/mongodb/mongodb.conf 5.3、进入主节点控制台1/data/mongodb/bin/mongo --port 30000 5.4、添加集群节点：1234567891011use admin;db.auth('admin','abc123');rs.initiate( &#123; _id : "testrepl", members: [ &#123; _id: 0, host: "10.0.7.53:30000" &#125;, &#123; _id: 1, host: "10.0.7.50:30000" &#125;, &#123; _id: 2, host: "10.0.7.51:30000","arbiterOnly" : true&#125; ]&#125;) 执行结果如下：1234567891011&#123; "ok" : 1, "operationTime" : Timestamp(1533388128, 1), "$clusterTime" : &#123; "clusterTime" : Timestamp(1533388128, 1), "signature" : &#123; "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="), "keyId" : NumberLong(0) &#125; &#125;&#125; 5.5、查看集群状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107MongoDB Enterprise testrepl:PRIMARY&gt; rs.status();&#123; "set" : "testrepl", "date" : ISODate("2018-08-04T13:09:25.894Z"), "myState" : 1, "term" : NumberLong(1), "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "heartbeatIntervalMillis" : NumberLong(2000), "optimes" : &#123; "lastCommittedOpTime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "readConcernMajorityOpTime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "appliedOpTime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "durableOpTime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125; &#125;, "lastStableCheckpointTimestamp" : Timestamp(1533388140, 1), "members" : [ &#123; "_id" : 0, "name" : "10.0.7.53:30000", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 289, "optime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-04T13:09:20Z"), "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "infoMessage" : "could not find member to sync from", "electionTime" : Timestamp(1533388139, 1), "electionDate" : ISODate("2018-08-04T13:08:59Z"), "configVersion" : 1, "self" : true, "lastHeartbeatMessage" : "" &#125;, &#123; "_id" : 1, "name" : "10.0.7.50:30000", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 37, "optime" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "optimeDurable" : &#123; "ts" : Timestamp(1533388160, 1), "t" : NumberLong(1) &#125;, "optimeDate" : ISODate("2018-08-04T13:09:20Z"), "optimeDurableDate" : ISODate("2018-08-04T13:09:20Z"), "lastHeartbeat" : ISODate("2018-08-04T13:09:25.051Z"), "lastHeartbeatRecv" : ISODate("2018-08-04T13:09:25.677Z"), "pingMs" : NumberLong(3), "lastHeartbeatMessage" : "", "syncingTo" : "10.0.7.53:30000", "syncSourceHost" : "10.0.7.53:30000", "syncSourceId" : 0, "infoMessage" : "", "configVersion" : 1 &#125;, &#123; "_id" : 2, "name" : "10.0.7.51:30000", "health" : 1, "state" : 7, "stateStr" : "ARBITER", "uptime" : 37, "lastHeartbeat" : ISODate("2018-08-04T13:09:25.031Z"), "lastHeartbeatRecv" : ISODate("2018-08-04T13:09:24.265Z"), "pingMs" : NumberLong(0), "lastHeartbeatMessage" : "", "syncingTo" : "", "syncSourceHost" : "", "syncSourceId" : -1, "infoMessage" : "", "configVersion" : 1 &#125; ], "ok" : 1, "operationTime" : Timestamp(1533388160, 1), "$clusterTime" : &#123; "clusterTime" : Timestamp(1533388160, 1), "signature" : &#123; "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="), "keyId" : NumberLong(0) &#125; &#125;&#125; 5.6、从库默认为不能读写模式，如果要启动从库的读模式，进入从库执行以下命令：1rs.slaveOk(); 5.7、增加一个仲裁节点，新增节点，配置文件中密钥文件、repl参数一定要保持一致：1rs.addArb("m1.example.net:27017") 5.8、添加一个新的从节点，添加之前设置该节点优先级为0，表决为0，以防止该节点数据未同步完成之前参与选举，待该节点数据同步完成之后，使用rs.reconfig()参数再修改其优先级和表决：1rs.add( &#123; host: "mongodb3.example.net:27017", priority: 0, votes: 0 &#125; ) rs.reconfig()命令执行如下：1234var cfg = rs.conf();cfg.members[4].priority = 1cfg.members[4].votes = 1rs.reconfig(cfg)]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Mongodb] mongdob-enterprise-4.0安装]]></title>
    <url>%2F2018%2F08%2F03%2Fmongdob4.0%2F</url>
    <content type="text"><![CDATA[1、Yum方式安装 1.1配置yum源 cat /etc/yum.repos.d/mongodb-enterprise.repo123456[mongodb-enterprise]name=MongoDB Enterprise Repositorybaseurl=https://repo.mongodb.com/yum/redhat/$releasever/mongodb-enterprise/4.0/$basearch/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc 1.2执行安装命令1sudo yum install -y mongodb-enterprise 如果想要指定安装某一个版本的mongodb,需要指定每一个组件的安装版本,如下所示：1sudo yum install -y mongodb-enterprise-4.0.0 mongodb-enterprise-server-4.0.0 mongodb-enterprise-shell-4.0.0 mongodb-enterprise-mongos-4.0.0 mongodb-enterprise-tools-4.0.0 1.3mongodb启动、关闭命令：123sudo service mongod startsudo service mongod stopsudo service mongod restart 1.4通过yum方式安装完之后，配置文件所在为/etc/mongod.conf 2、tar包方式安装 2.1安装之前需要，安装依赖包： linux-6:1yum install -y cyrus-sasl cyrus-sasl-plain cyrus-sasl-gssapi krb5-libs libcurl libpcap net-snmp openldap openssl linux-71yum install -y cyrus-sasl cyrus-sasl-gssapi cyrus-sasl-plain krb5-libs libcurl libpcap lm_sensors-libs net-snmp net-snmp-agent-libs openldap openssl rpm-libs tcp_wrappers-libs 2.2下载mongodb-enterprise软件包1wget https://downloads.mongodb.com/linux/mongodb-linux-x86_64-enterprise-rhel70-4.0.0.tgz 2.3解压软件包，修改目录名称，配置环境变量1234 tar -zxvf mongodb-linux-x86_64-enterprise-rhel70-4.0.0.tgz -C /data/ mv /data/mongodb-linux-x86_64-enterprise-rhel70-4.0.0 /data/mongodbecho "export PATH=/data/mongodb/bin:\$PATH" &gt;&gt; ~/.bash_profilesource ~/.bash_profile 2.4修改配置文件 cat /data/mongodb/mongodb.conf1234567891011121314151617181920212223242526272829303132333435# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/# where to write logging data.systemLog: destination: file logAppend: true path: /data/mongodb/log/mongod.log# Where and how to store data.storage: dbPath: /data/mongodb/data/ journal: enabled: true# engine:# mmapv1:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /data/mongodb/log/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo# network interfacesnet: port: 30000 bindIp: 127.0.0.1,10.0.7.51 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.#security:#operationProfiling:#replication:#sharding:## Enterprise-Only Options#auditLog:#snmp: 2.5修改的配置文件中，如果数据目录，日志目录不存在会报错，需要手动配置：1mkdir -p /data/mongodb/&#123;log,data&#125; 2.6启动mongodb123456shell&gt;/data/mongodb/bin/mongod -f /data/mongodb/mongodb.conf -------- 2018-08-03T08:42:19.873+0000 I CONTROL [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'about to fork child process, waiting until server is ready for connections.forked process: 41022child process started successfully, parent exiting 2.7查看mongodb进程：1234 netstat -tunlp|grep 30000---------tcp 0 0 10.0.7.51:30000 0.0.0.0:* LISTEN 41022/mongod tcp 0 0 127.0.0.1:30000 0.0.0.0:* LISTEN 41022/mongod]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Zabbix] zabbix3.4监控nginx性能]]></title>
    <url>%2F2018%2F08%2F03%2Fzabbix-nginx%2F</url>
    <content type="text"><![CDATA[1、查看nginx安装HTTP Stub Status1openresty -V 如果”–with-http_stub_status_module”参数，表示没有安装，要手动添加：12在编译nginx 的时候要加上参数 –with-http_stub_status_module，执行./configure &amp;&amp; make就可以了，不用make install。不过，一般情况下都是安装了的。 2、nginx服务器添加配置 2.1添加配置文件nginx_status.confcat /usr/local/openresty/nginx/conf/conf.d/nginx_status.conf12345678server &#123; listen 80; server_name 127.0.0.1; location /basic_status &#123; stub_status; &#125;&#125; 2.2重新加载配置文件1openresty -s reload 2.3获取nginx监控状态123456curl http://127.0.0.1/basic_status-------------Active connections: 1 server accepts handled requests 572 572 764 Reading: 0 Writing: 1 Waiting: 0 nginx监控参数详解123456## Active connections: 对后端发起的活动连接数## Server accepts handled requests: Nginx 总共处理了 572 个连接，成功创建了 572 次握手（没有失败次数），总共处理了 764 个请求## Reading: Nginx 读取到客户端的 Header 信息数## Writing: Nginx 返回给客户端的 Header 信息数## Waiting: 开启 keep-alive 的情况下，这个值等于 active - ( reading + writing ), 意思是 Nginx 已经处理完成，正在等待下一次请求指令的驻留连接## 在访问效率很高，请求很快被处理完毕的情况下，Waiting 数比较多是正常的。如果 reading + writing 数较多，则说明并发访问量很大，正在处理过程中 3、配置zabbix创建存放脚本目录，（我的zabbix安装路径为 /usr/local/zabbix）：12mkdir /usr/local/zabbix/scriptcd /usr/local/zabbix/script 创建存放数据文件（可自行定义）：1touch .status.txt 编辑脚本用于获取nginx监控状态参数：12345678910111213141516171819202122232425echo "#!/bin/bashserver_hostname=127.0.0.1data_file=/usr/local/zabbix/script/.status.txtstatus_data=\`curl -o \$data_file -s http://\$server_hostname/basic_status\`function Active() &#123; awk -F \"[: ]\" '/Active/&#123;print \$4&#125;' \$data_file&#125; function Reading() &#123; awk -F \"[: ]\" '/Reading/ &#123;print \$3&#125;' \$data_file&#125;function Writing() &#123; awk -F \"[: ]\" '/Writing/ &#123;print \$6&#125;' \$data_file&#125;function Waiting() &#123; awk -F \"[: ]\" '/Waiting/ &#123;print \$9&#125;' \$data_file&#125;\$1" &gt; /usr/local/zabbix/script/nginx_connection.sh 修改目录下所有文件的权限，否则脚本写入文件会有权限问题1chown -R zabbix.zabbix /usr/local/zabbix/script 添加zabbix参数到agent配置文件1234echo \"UserParameter=nginx.Active,sh /usr/local/zabbix/script/nginx_connection.sh ActiveUserParameter=nginx.Writing,sh /usr/local/zabbix/script/nginx_connection.sh WritingUserParameter=nginx.Reading,sh /usr/local/zabbix/script/nginx_connection.sh ReadingUserParameter=nginx.Waiting,sh /usr/local/zabbix/script/nginx_connection.sh Waiting\" &gt;&gt; /usr/local/zabbix/etc/zabbix_agentd.conf 重新启动agent客户端：1/etc/init.d/zabbix_agentd restart 在server端测试是否能获取到参数：1/usr/local/zabbix/bin/zabbix_get -s 10.1.130.47 -k nginx.Active]]></content>
      <tags>
        <tag>linux</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Redis] redis-cluster集群部署]]></title>
    <url>%2F2018%2F08%2F02%2Fredis-cluster%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[0、Redis 集群功能限制123456Redis集群相对单机在功能上有一定限制。key批量操作支持有限。如：MSET``MGET，目前只支持具有相同slot值的key执行批量操作。key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list。不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db 0。复制结构只支持一层，不支持嵌套树状复制结构。 1、服务器三台，在每台服务器上部署两个redis服务器，节点信息如下：123主1：10.0.7.53-6379, 10.0.7.53-6380主2：10.0.7.50-6379, 10.0.7.50-6380主3：10.0.7.51-6379, 10.0.7.51-6380 2、修改redis.conf配置文件cat /data/redis/etc/redis6379.conf(不同服务器，修改bind对应的ip即可)123456789101112pidfile /data/redis6379/log/redis.pidbind 10.0.7.53port 6379daemonize yeslogfile /data/redis6379/log/redis.logdir /data/redis6379/databases 16maxmemory 1gcluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yes cat /data/redis/etc/redis6380.conf(不同服务器，修改bind对应的ip即可)123456789101112pidfile /data/redis6380/log/redis.pidbind 10.0.7.53port 6380daemonize yeslogfile /data/redis6380/log/redis.logdir /data/redis6380/databases 16maxmemory 1gcluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yes 创建指定的文件目录(指定目录不存在，启动会报错)12mkdir -p /data/redis6379/log/mkdir -p /data/redis6380/log/ 3、启动redis服务3.1启动服务之前，修改内核参数：12345678910echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled添加到开机自动启动/etc/rc.localecho 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' &gt;&gt; /etc/rc.localchmod +x /etc/rc.d/rc.localecho "vm.overcommit_memory = 1" &gt;&gt; /etc/sysctl.conf使修改环境变量生效sysctl vm.overcommit_memory=1echo 511 &gt; /proc/sys/net/core/somaxconn 3.2在三个服务器上，分别启动redis服务12/data/redis/src/redis-server /data/redis/etc/redis6379.conf/data/redis/src/redis-server /data/redis/etc/redis6380.conf 4、启动成功之后，在指定的dir目录下回生成一个nodes.conf的文件123cat /data/redis6379/nodes.conf4933ef69f73b390098a4431449aeef2e83dacfc0 :0@0 myself,master - 0 0 0 connectedvars currentEpoch 0 lastVoteEpoch 0 该文件记录了节点信息id，不随主机名和端口的改变而改变。 5、开始配置集群5.1配置集群需要安装ruby12345678910yum install -y ruby安装完成之后运行：gem install redis提示报错：----------Fetching: redis-4.0.1.gem (100%)ERROR: Error installing redis: redis requires Ruby version &gt;= 2.2.2.------------默认yum安装ruby版本为2.0.0，但是安装redis-trib.rb运行的环境，最少需要ruby-2.2.2版本 5.2需要先安装rvm，升级ruby版本1234567891011121314151617181920212223242526安装curl：sudo yum install curl安装RVMcurl -L get.rvm.io | bash -s stable安装如果提示没有public key,按提示在命令行输入信息：shell&gt; gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3-----gpg: Can't check signature: No public keyWarning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures).GPG signature verification failed for '/usr/local/rvm/archives/rvm-1.29.4.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.4/1.29.4.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3------------------------------使rvm环境变量生效source /usr/local/rvm/scripts/rvm查看rvm库中已知的ruby版本rvm list known安装一个ruby版本rvm install 2.5.1使用一个ruby版本rvm use 2.5.1卸载已安装的旧版本rvm remove 2.0.0查看版本ruby --version 5.3再安装redis就可以了1gem install redis 5.4安装完成之后，执行以下命令创建一个新的集群 1/data/redis/src/redis-trib.rb create --replicas 1 10.0.7.53:6379 10.0.7.53:6380 10.0.7.50:6379 10.0.7.50:6380 10.0.7.51:6379 10.0.7.51:6380 –replicas 1：该参数代表为每一个主节点增加一个从节点 123&gt;&gt;&gt; Creating cluster[ERR] Sorry, can&apos;t connect to node 10.0.7.53:6379创建集群报错，确认gem版本没有问题，查看配置文件是否存在requirpass等参数 重新执行创建集群1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:10.0.7.53:637910.0.7.50:637910.0.7.51:6379Adding replica 10.0.7.50:6380 to 10.0.7.53:6379Adding replica 10.0.7.51:6380 to 10.0.7.50:6379Adding replica 10.0.7.53:6380 to 10.0.7.51:6379M: 4933ef69f73b390098a4431449aeef2e83dacfc0 10.0.7.53:6379 slots:0-5460 (5461 slots) masterS: 3f757295e082a5fbe237015862d0a502779f3adf 10.0.7.53:6380 replicates 3e31b1ceded27ad5b4114beaebb559d7f5ca465dM: 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4 10.0.7.50:6379 slots:5461-10922 (5462 slots) masterS: 5b3aa1532d911e1a9b966ec53e3203a3221056e3 10.0.7.50:6380 replicates 4933ef69f73b390098a4431449aeef2e83dacfc0M: 3e31b1ceded27ad5b4114beaebb559d7f5ca465d 10.0.7.51:6379 slots:10923-16383 (5461 slots) masterS: 30aabebd554d34e59584774feebd472f622f1cc2 10.0.7.51:6380 replicates 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4Can I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join...&gt;&gt;&gt; Performing Cluster Check (using node 10.0.7.53:6379)M: 4933ef69f73b390098a4431449aeef2e83dacfc0 10.0.7.53:6379 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4 10.0.7.50:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)M: 3e31b1ceded27ad5b4114beaebb559d7f5ca465d 10.0.7.51:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 30aabebd554d34e59584774feebd472f622f1cc2 10.0.7.51:6380 slots: (0 slots) slave replicates 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4S: 3f757295e082a5fbe237015862d0a502779f3adf 10.0.7.53:6380 slots: (0 slots) slave replicates 3e31b1ceded27ad5b4114beaebb559d7f5ca465dS: 5b3aa1532d911e1a9b966ec53e3203a3221056e3 10.0.7.50:6380 slots: (0 slots) slave replicates 4933ef69f73b390098a4431449aeef2e83dacfc0[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.---------------------------------- 5.5集群安装完成，查看集群状态12345678910111213141516171819202122/data/redis/src/redis-trib.rb check 10.0.7.53:6379（或者 进入控制台/data/redis/src/redis-cli -h 10.0.7.53，输入 CLUSTER nodes)&gt;&gt;&gt; Performing Cluster Check (using node 10.0.7.53:6379)M: 4933ef69f73b390098a4431449aeef2e83dacfc0 10.0.7.53:6379 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4 10.0.7.50:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)M: 3e31b1ceded27ad5b4114beaebb559d7f5ca465d 10.0.7.51:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 30aabebd554d34e59584774feebd472f622f1cc2 10.0.7.51:6380 slots: (0 slots) slave replicates 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4S: 3f757295e082a5fbe237015862d0a502779f3adf 10.0.7.53:6380 slots: (0 slots) slave replicates 3e31b1ceded27ad5b4114beaebb559d7f5ca465dS: 5b3aa1532d911e1a9b966ec53e3203a3221056e3 10.0.7.50:6380 slots: (0 slots) slave replicates 4933ef69f73b390098a4431449aeef2e83dacfc0[OK] All nodes agree about slots configuration. 6、集群安装完成，测试集群是否正常运行6.1杀掉任意一个主节点，从节点自动切换为主，1234567891011121314151617/data/redis/src/redis-trib.rb check 10.0.7.53:6380&gt;&gt;&gt; Performing Cluster Check (using node 10.0.7.53:6380)S: 3f757295e082a5fbe237015862d0a502779f3adf 10.0.7.53:6380 slots: (0 slots) slave replicates 3e31b1ceded27ad5b4114beaebb559d7f5ca465dM: 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4 10.0.7.50:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)M: 5b3aa1532d911e1a9b966ec53e3203a3221056e3 10.0.7.50:6380 slots:0-5460 (5461 slots) master 0 additional replica(s)S: 30aabebd554d34e59584774feebd472f622f1cc2 10.0.7.51:6380 slots: (0 slots) slave replicates 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4M: 3e31b1ceded27ad5b4114beaebb559d7f5ca465d 10.0.7.51:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s) 6.2重新启动别杀掉的节点之后，该节点自动变为从：1234567891011121314151617181920/data/redis/src/redis-trib.rb check 10.0.7.53:6380&gt;&gt;&gt; Performing Cluster Check (using node 10.0.7.53:6380)S: 3f757295e082a5fbe237015862d0a502779f3adf 10.0.7.53:6380 slots: (0 slots) slave replicates 3e31b1ceded27ad5b4114beaebb559d7f5ca465dM: 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4 10.0.7.50:6379 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 4933ef69f73b390098a4431449aeef2e83dacfc0 10.0.7.53:6379 slots: (0 slots) slave replicates 5b3aa1532d911e1a9b966ec53e3203a3221056e3M: 5b3aa1532d911e1a9b966ec53e3203a3221056e3 10.0.7.50:6380 slots:0-5460 (5461 slots) master 1 additional replica(s)S: 30aabebd554d34e59584774feebd472f622f1cc2 10.0.7.51:6380 slots: (0 slots) slave replicates 27eb4895dc9369adcd81d9a00709dfbf6fbbd0d4M: 3e31b1ceded27ad5b4114beaebb559d7f5ca465d 10.0.7.51:6379 slots:10923-16383 (5461 slots) master 1 additional replica(s)]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Linux] centos7.4--yum install gcc报错]]></title>
    <url>%2F2018%2F08%2F02%2Fcentos7.4yum%E5%AE%89%E8%A3%85gcc%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[[yum install gcc执行报错如下：]12345678910111213141516171819202122232425262728293031323334353637383940414243Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package gcc.x86_64 0:4.8.5-28.el7_5.1 will be installed--&gt; Processing Dependency: libgomp = 4.8.5-28.el7_5.1 for package: gcc-4.8.5-28.el7_5.1.x86_64--&gt; Processing Dependency: cpp = 4.8.5-28.el7_5.1 for package: gcc-4.8.5-28.el7_5.1.x86_64--&gt; Processing Dependency: glibc-devel &gt;= 2.2.90-12 for package: gcc-4.8.5-28.el7_5.1.x86_64--&gt; Processing Dependency: libmpfr.so.4()(64bit) for package: gcc-4.8.5-28.el7_5.1.x86_64--&gt; Processing Dependency: libmpc.so.3()(64bit) for package: gcc-4.8.5-28.el7_5.1.x86_64--&gt; Running transaction check---&gt; Package cpp.x86_64 0:4.8.5-28.el7_5.1 will be installed---&gt; Package glibc-devel.x86_64 0:2.17-222.el7 will be installed--&gt; Processing Dependency: glibc-headers = 2.17-222.el7 for package: glibc-devel-2.17-222.el7.x86_64--&gt; Processing Dependency: glibc = 2.17-222.el7 for package: glibc-devel-2.17-222.el7.x86_64--&gt; Processing Dependency: glibc-headers for package: glibc-devel-2.17-222.el7.x86_64---&gt; Package libgomp.x86_64 0:4.8.5-11.el7 will be updated---&gt; Package libgomp.x86_64 0:4.8.5-28.el7_5.1 will be an update---&gt; Package libmpc.x86_64 0:1.0.1-3.el7 will be installed---&gt; Package mpfr.x86_64 0:3.1.1-4.el7 will be installed--&gt; Running transaction check---&gt; Package glibc.x86_64 0:2.17-157.el7_3.5 will be updated--&gt; Processing Dependency: glibc = 2.17-157.el7_3.5 for package: glibc-common-2.17-157.el7_3.5.x86_64---&gt; Package glibc.x86_64 0:2.17-222.el7 will be an update---&gt; Package glibc-headers.x86_64 0:2.17-222.el7 will be installed--&gt; Processing Dependency: kernel-headers &gt;= 2.2.1 for package: glibc-headers-2.17-222.el7.x86_64--&gt; Processing Dependency: kernel-headers for package: glibc-headers-2.17-222.el7.x86_64--&gt; Running transaction check---&gt; Package glibc.x86_64 0:2.17-157.el7_3.5 will be updated--&gt; Processing Dependency: glibc = 2.17-157.el7_3.5 for package: glibc-common-2.17-157.el7_3.5.x86_64---&gt; Package kernel-headers.x86_64 0:3.10.0-862.9.1.el7 will be installed--&gt; Finished Dependency ResolutionError: Package: glibc-common-2.17-157.el7_3.5.x86_64 (@CentOS-Updates) Requires: glibc = 2.17-157.el7_3.5 Removing: glibc-2.17-157.el7_3.5.x86_64 (@CentOS-Updates) glibc = 2.17-157.el7_3.5 Updated By: glibc-2.17-222.el7.x86_64 (base) glibc = 2.17-222.el7 You could try using --skip-broken to work around the problem** Found 3 pre-existing rpmdb problem(s), 'yum check' output follows:glibc-common-2.17-222.el7.x86_64 is a duplicate with glibc-common-2.17-157.el7_3.5.x86_64glibc-common-2.17-222.el7.x86_64 has missing requires of glibc = ('0', '2.17', '222.el7')libgcc-4.8.5-28.el7_5.1.x86_64 is a duplicate with libgcc-4.8.5-11.el7.x86_64 产生该问题的主要原因是：在系统upgrade的时候，残存了上一个版本的软件包 [解决办法：]首先安装 yum-utils 套件1yum install yum-utils 执行clean duplicate package 1package-cleanup --cleandupes 重新安装glibc1yum reinstall glibc glibc-common libgcc 安装完成之后再安装gcc1yum install gcc]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Redis] redis-sentinel集群配置（一主两从三哨兵）]]></title>
    <url>%2F2018%2F08%2F01%2Fredis-sentinel%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE(%E4%B8%80%E4%B8%BB%E4%B8%A4%E4%BB%8E%E4%B8%89%E5%93%A8%E5%85%B5)%2F</url>
    <content type="text"><![CDATA[1、所有节点安装redis节点信息：主1：10.0.7.53从2：10.0.7.50从3：10.0.7.51除了在三个节点部署redis服务，再分别部署sentinel。 2、配置主从，在主节点配置文件添加如下配置：主节点1配置：123456789101112131415161718pidfile /data/redis/log/redis.pidbind 10.0.7.53port 6379daemonize yeslogfile "/data/redis/log/redis.log"databases 16maxmemory 1grequirepass 123456masterauth 123456slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-ping-slave-period 10repl-timeout 60repl-disable-tcp-nodelay norepl-backlog-size 5mbrepl-backlog-ttl 3600 从节点2配置：12345678910111213141516171819pidfile /data/redis/log/redis.pidbind 10.0.7.50port 6379daemonize yeslogfile "/data/redis/log/redis.log"databases 16maxmemory 1gslaveof 10.0.7.53 6379masterauth 123456requirepass 123456slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-ping-slave-period 10repl-timeout 60repl-disable-tcp-nodelay norepl-backlog-size 5mbrepl-backlog-ttl 3600 从节点3配置：12345678910111213141516171819pidfile /data/redis/log/redis.pidbind 10.0.7.50port 6379daemonize yeslogfile "/data/redis/log/redis.log"databases 16maxmemory 1gslaveof 10.0.7.53 6379masterauth 123456requirepass 123456slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-ping-slave-period 10repl-timeout 60repl-disable-tcp-nodelay norepl-backlog-size 5mbrepl-backlog-ttl 3600 上面配置相关参数详解：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#复制选项，slave复制对应的master。slaveof &lt;masterip&gt; &lt;masterport&gt;#如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。masterauth &lt;master-password&gt; ------------------------------------- 如果主库配置了密码，从库没有添加这行数据，会报一下错误： # Unexpected reply to PSYNC from master: -NOAUTH Authentication required. * Retrying with SYNC... # MASTER aborted replication with an error: NOAUTH Authentication required. -------------------------------------#当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。slave-serve-stale-data yes#作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。slave-read-only yes#是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no#diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。repl-diskless-sync-delay 5#slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。# repl-ping-slave-period 10#复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。# repl-timeout 60#是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。repl-disable-tcp-nodelay no#复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。# repl-backlog-size 5mb#master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。# repl-backlog-ttl 3600#当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。slave-priority 100#redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。# min-slaves-to-write 3#延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。# min-slaves-max-lag 10 3、修改哨兵配置文件cat sentinel.conf123456789101112131415port 26379dir "/tmp/sentinel"logfile "/tmp/sentinel.log"daemonize yessentinel monitor mymaster 10.0.7.53 6379 2sentinel down-after-milliseconds mymaster 5000sentinel parallel-syncs mymaster 1sentinel auth-pass mymaster 123456sentinel failover-timeout mymaster 180000sentinel config-epoch mymaster 2sentinel leader-epoch mymaster 2sentinel known-slave mymaster 10.0.7.51 6379sentinel known-slave mymaster 10.0.7.50 6379sentinel current-epoch 2protected-mode no 指定的dir路径若不存在需要手动创建：1mkdir -p /tmp/sentinel sentinel相关配置参数详解：12345678910111213#sentinel monitor mymaster 10.0.7.53 6379 2// 当前Sentinel节点监控 127.0.0.1:6379 这个主节点// 2代表判断主节点失败至少需要2个Sentinel节点节点同意// mymaster是主节点的别名#sentinel down-after-milliseconds mymaster 30000//每个Sentinel节点都要定期PING命令来判断Redis数据节点和其余Sentinel节点是否可达，如果超过30000毫秒且没有回复，则判定不可达#sentinel parallel-syncs mymaster 1//当Sentinel节点集合对主节点故障判定达成一致时，Sentinel领导者节点会做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，限制每次向新的主节点发起复制操作的从节点个数为1#sentinel failover-timeout mymaster 180000//故障转移超时时间为180000毫秒 4、启动服务各服务器启动redis服务1/data/redis/src/redis-server /data/redis/etc/redis.conf 各服务器启动sentinel服务1/data/redis/src/redis-sentinel /data/redis/sentinel.conf 查看集群信息1/data/redis/src/redis-cli -h 127.0.0.1 -p 26379 INFO Sentinel]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Python] python-2.7升级到python-3.7]]></title>
    <url>%2F2018%2F07%2F30%2Fpython-2.7%E5%8D%87%E7%BA%A7%E5%88%B0python-3.7%2F</url>
    <content type="text"><![CDATA[[下载、解压python3.7]12wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xztar -xvf Python-3.7.0.tar.xz [安装编译]123cd Python-3.7.0/./configure --prefix=/usr/local/python3.7make &amp;&amp; make install [安装报错]12ModuleNotFoundError: No module named '_ctypes'make: *** [install] Error 1 解决方法： 安装libffi-devel yum install libffi-devel 重新编译安装 make &amp;&amp; make install [备份旧版本的python]123456789ll /usr/bin/python*lrwxrwxrwx. 1 root root 7 Apr 10 19:35 /usr/bin/python -&gt; python2lrwxrwxrwx. 1 root root 9 Apr 10 19:35 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7-------------------------一般自带系统已经做好了python2.7的备份，直接替换掉python即可如果没有备份，使用一些命令备份：mv /usr/bin/python /usr/bin/python_old #备份旧的python [新版本python软连接到python]12345rm -rf /usr/bin/python #需要删除旧版的python,否则报错ln -s /usr/local/python3.7/bin/python3.7 /usr/bin/python #添加软连接python -V #查看python版本2.7版本没有pip,升级到python3.7后，自带有pip,做一个pip的软连接即可ln -s /usr/local/python3.7/bin/pip3 /usr/bin/pip [升级完python之后，yum命令失效，需修改配置文件]使用yum命令报以下错误：12345 yum clean all File "/usr/bin/yum", line 30 except KeyboardInterrupt, e: ^SyntaxError: invalid syntax 解决 yum 不可用：1234修改/usr/bin/yum配置文件#!/usr/bin/python 改成： #!/usr/bin/python2.7重新测试yum是否正常：yum clean all [升级完python之后，yum使用过程中，额外问题：]123456yum install tree -y ----------------------------------报错：File "/usr/libexec/urlgrabber-ext-down", line 28 except OSError, e:--------------------------------- 解决方法：12修改/usr/libexec/urlgrabber-ext-down配置文件#!/usr/bin/python 改成： #!/usr/bin/python2.7]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[About Me]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[愿你被这个世界温柔以待，即使生活总以刻薄荒芜相欺！]]></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
